{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LexicalRetrieval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhilasha-kumar/modeling-lexical-retrieval/blob/main/LexicalRetrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkUSyf_WeMwt"
      },
      "source": [
        "# Allow drive access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bFV9y2TXkgz",
        "outputId": "f856d220-7807-4e56-d8d2-43ec8f36e934"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53eYB-A0eP98"
      },
      "source": [
        "# GPU access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2HxbC0YYEkR",
        "outputId": "16d2ac60-fc20-4001-f1ac-3e1ed2ad255e"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Thu Dec  2 03:40:34 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    59W / 149W |    145MiB / 11441MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cmvK8BJ8SV5"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import heapq\n",
        "import itertools\n",
        "import scipy.spatial.distance\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from numpy.random import randint\n",
        "from scipy.special import softmax\n",
        "from sklearn.preprocessing import MinMaxScaler, normalize\n",
        "from numpy.linalg import matrix_power\n",
        "from functools import lru_cache\n",
        "import glob\n",
        "from scipy.special import expit\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from functools import lru_cache\n",
        "from itertools import product as iterprod\n",
        "import itertools\n",
        "from nltk.metrics import *\n",
        "import re"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgV7A0mY8v2s"
      },
      "source": [
        "# Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gycn2xZ08Ul2",
        "outputId": "e8300446-fec9-4e6b-d480-ce3cd8aaffeb"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  julie_files = pd.read_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/Julie_2021data.csv\", encoding= 'unicode_escape')\n",
        "  vocab = pd.read_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/julie_vocab.csv\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "bBtAAkWcB25V",
        "outputId": "f5578d37-9d0c-44d1-f5f3-84518230d37f"
      },
      "source": [
        "julie_files.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>StudyNo</th>\n",
              "      <th>AgeGroup</th>\n",
              "      <th>PrimeInstruction</th>\n",
              "      <th>ExperimentName</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Procedure</th>\n",
              "      <th>Trial</th>\n",
              "      <th>Both</th>\n",
              "      <th>Neither</th>\n",
              "      <th>Phonological</th>\n",
              "      <th>Semantic</th>\n",
              "      <th>Prime</th>\n",
              "      <th>PrimeCondition</th>\n",
              "      <th>Question.RESP</th>\n",
              "      <th>State.RT</th>\n",
              "      <th>FreeResp</th>\n",
              "      <th>Resp</th>\n",
              "      <th>FreeResp.RT</th>\n",
              "      <th>NewAccuracy</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>FreeRespPrimeIntrusion</th>\n",
              "      <th>Target</th>\n",
              "      <th>MCCorrect</th>\n",
              "      <th>McResp</th>\n",
              "      <th>McAcc</th>\n",
              "      <th>McRT</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>McActualResp</th>\n",
              "      <th>WhichPrime</th>\n",
              "      <th>ToEliminate</th>\n",
              "      <th>prompt</th>\n",
              "      <th>both_prompt</th>\n",
              "      <th>neither_prompt</th>\n",
              "      <th>sem_prompt</th>\n",
              "      <th>phon_prompt</th>\n",
              "      <th>prime_prompt</th>\n",
              "      <th>target_prompt</th>\n",
              "      <th>resp_prompt</th>\n",
              "      <th>target_both</th>\n",
              "      <th>target_neither</th>\n",
              "      <th>target_sem</th>\n",
              "      <th>target_phon</th>\n",
              "      <th>target_prime</th>\n",
              "      <th>target_resp</th>\n",
              "      <th>lev_target_both</th>\n",
              "      <th>lev_target_neither</th>\n",
              "      <th>lev_target_sem</th>\n",
              "      <th>lev_target_phon</th>\n",
              "      <th>lev_target_prime</th>\n",
              "      <th>lev_target_resp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Old</td>\n",
              "      <td>NotThePrime</td>\n",
              "      <td>tot not the prime</td>\n",
              "      <td>701</td>\n",
              "      <td>ExpProc1</td>\n",
              "      <td>1</td>\n",
              "      <td>avoid</td>\n",
              "      <td>dove</td>\n",
              "      <td>absolve</td>\n",
              "      <td>refuse</td>\n",
              "      <td>ABSOLVE</td>\n",
              "      <td>P</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12345</td>\n",
              "      <td>1527</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>abstain</td>\n",
              "      <td>c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>refuse</td>\n",
              "      <td>dove</td>\n",
              "      <td>abstain</td>\n",
              "      <td>absolve</td>\n",
              "      <td>avoid</td>\n",
              "      <td>0</td>\n",
              "      <td>X</td>\n",
              "      <td>0</td>\n",
              "      <td>To refrain deliberately and often with an effo...</td>\n",
              "      <td>0.066920</td>\n",
              "      <td>-0.033121</td>\n",
              "      <td>0.171530</td>\n",
              "      <td>0.127612</td>\n",
              "      <td>0.127612</td>\n",
              "      <td>0.125816</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.312840</td>\n",
              "      <td>0.089485</td>\n",
              "      <td>0.464569</td>\n",
              "      <td>0.217932</td>\n",
              "      <td>0.217932</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>Old</td>\n",
              "      <td>NotThePrime</td>\n",
              "      <td>tot not the prime</td>\n",
              "      <td>701</td>\n",
              "      <td>ExpProc1</td>\n",
              "      <td>2</td>\n",
              "      <td>Norderstedt</td>\n",
              "      <td>image</td>\n",
              "      <td>neurosurgery</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>NORDERSTEDT</td>\n",
              "      <td>B</td>\n",
              "      <td>2</td>\n",
              "      <td>6947</td>\n",
              "      <td>0</td>\n",
              "      <td>12345</td>\n",
              "      <td>1060</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nuremberg</td>\n",
              "      <td>d</td>\n",
              "      <td>d</td>\n",
              "      <td>1</td>\n",
              "      <td>7385</td>\n",
              "      <td>Norderstedt</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>image</td>\n",
              "      <td>Nuremberg</td>\n",
              "      <td>neurosurgery</td>\n",
              "      <td>Nuremberg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>German city for which antisemitic laws were na...</td>\n",
              "      <td>0.020833</td>\n",
              "      <td>-0.096533</td>\n",
              "      <td>0.164941</td>\n",
              "      <td>0.021730</td>\n",
              "      <td>0.020833</td>\n",
              "      <td>0.225719</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.180054</td>\n",
              "      <td>0.007681</td>\n",
              "      <td>0.428896</td>\n",
              "      <td>0.328091</td>\n",
              "      <td>0.180054</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Old</td>\n",
              "      <td>NotThePrime</td>\n",
              "      <td>tot not the prime</td>\n",
              "      <td>701</td>\n",
              "      <td>ExpProc1</td>\n",
              "      <td>3</td>\n",
              "      <td>hematoma</td>\n",
              "      <td>window</td>\n",
              "      <td>homeowner</td>\n",
              "      <td>contusion</td>\n",
              "      <td>HEMATOMA</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>5920</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12345</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hemorrhage</td>\n",
              "      <td>d</td>\n",
              "      <td>d</td>\n",
              "      <td>1</td>\n",
              "      <td>5430</td>\n",
              "      <td>hematoma</td>\n",
              "      <td>contusion</td>\n",
              "      <td>window</td>\n",
              "      <td>hemorrhage</td>\n",
              "      <td>homeowner</td>\n",
              "      <td>hemorrhage</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The escape of blood from vessels, including in...</td>\n",
              "      <td>0.155783</td>\n",
              "      <td>0.027197</td>\n",
              "      <td>0.066568</td>\n",
              "      <td>-0.063326</td>\n",
              "      <td>0.155783</td>\n",
              "      <td>0.326574</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.653506</td>\n",
              "      <td>0.210072</td>\n",
              "      <td>0.458587</td>\n",
              "      <td>0.151632</td>\n",
              "      <td>0.653506</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Old</td>\n",
              "      <td>NotThePrime</td>\n",
              "      <td>tot not the prime</td>\n",
              "      <td>701</td>\n",
              "      <td>ExpProc1</td>\n",
              "      <td>4</td>\n",
              "      <td>Saigon</td>\n",
              "      <td>thigh</td>\n",
              "      <td>sofa</td>\n",
              "      <td>Tokyo</td>\n",
              "      <td>THIGH</td>\n",
              "      <td>U</td>\n",
              "      <td>1</td>\n",
              "      <td>4833</td>\n",
              "      <td>seoul</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>3272</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>b</td>\n",
              "      <td>b</td>\n",
              "      <td>1</td>\n",
              "      <td>4168</td>\n",
              "      <td>sofa</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Saigon</td>\n",
              "      <td>thigh</td>\n",
              "      <td>Tokyo</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Capital of South Korea</td>\n",
              "      <td>0.270083</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.378604</td>\n",
              "      <td>0.100953</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.609253</td>\n",
              "      <td>0.609253</td>\n",
              "      <td>0.424191</td>\n",
              "      <td>0.144735</td>\n",
              "      <td>0.464015</td>\n",
              "      <td>0.166060</td>\n",
              "      <td>0.144735</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>Old</td>\n",
              "      <td>NotThePrime</td>\n",
              "      <td>tot not the prime</td>\n",
              "      <td>701</td>\n",
              "      <td>ExpProc1</td>\n",
              "      <td>5</td>\n",
              "      <td>Heinola</td>\n",
              "      <td>shop</td>\n",
              "      <td>handkerchief</td>\n",
              "      <td>Oslo</td>\n",
              "      <td>OSLO</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>7553</td>\n",
              "      <td>helsinki</td>\n",
              "      <td>Helsinki</td>\n",
              "      <td>3497</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Helsinki</td>\n",
              "      <td>d</td>\n",
              "      <td>d</td>\n",
              "      <td>1</td>\n",
              "      <td>3366</td>\n",
              "      <td>Heinola</td>\n",
              "      <td>Oslo</td>\n",
              "      <td>shop</td>\n",
              "      <td>Helsinki</td>\n",
              "      <td>handkerchief</td>\n",
              "      <td>Helsinki</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Capital of Finland</td>\n",
              "      <td>0.034701</td>\n",
              "      <td>-0.015010</td>\n",
              "      <td>0.383043</td>\n",
              "      <td>-0.002959</td>\n",
              "      <td>0.383043</td>\n",
              "      <td>0.575294</td>\n",
              "      <td>0.575294</td>\n",
              "      <td>0.222391</td>\n",
              "      <td>0.110593</td>\n",
              "      <td>0.546045</td>\n",
              "      <td>0.080330</td>\n",
              "      <td>0.546045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ...  lev_target_prime  lev_target_resp\n",
              "0           0             0  ...          0.333333              NaN\n",
              "1           1             1  ...          0.142857              NaN\n",
              "2           2             2  ...          0.375000              NaN\n",
              "3           3             3  ...          0.000000              1.0\n",
              "4           4             4  ...          0.125000              1.0\n",
              "\n",
              "[5 rows x 57 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzBs_-3G85P2"
      },
      "source": [
        "# Import USE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y29lkvMWebIT"
      },
      "source": [
        "The Universal Sentence Encoder uses two different architctures to encode a string of any length into a compact high-dimensional vector representation -- the Deep Averaging Network (which is more of a bag-of-words approach) and the Transformer network (more predictive, attention-based). See link above for more details -- but DAN is generally faster and slightly less accurate than the Transformer model on NLP tasks (we might want to compare both). Below we see some examples of how we can use these \"vectors\" to find \"closest neighbors\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyMKr_vB8hck",
        "outputId": "bfd06cfc-aa49-48fc-e12d-024590088618"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "dan_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "#transformer_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\" \n",
        "model = hub.load(dan_url)\n",
        "print (\"module %s loaded\" % dan_url)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9DrYP8S61Qq",
        "outputId": "863143a3-814d-4072-d7df-7fd80c9c3020"
      },
      "source": [
        "model([\"Finland\"])[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0MFBFD1eaTl"
      },
      "source": [
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "nIa2gruXfg2F",
        "outputId": "5cf7ad22-e685-44ad-9d03-8e85b97bdc50"
      },
      "source": [
        "sent1 = \"Capital of Finland\"\n",
        "print(\"prompt is:\", sent1)\n",
        "sent1_vec = model([sent1])[0]\n",
        "print(\"sent1_vec is a numpy array of shape:\", sent1_vec.shape)\n",
        "resp = list(vocab.vocab_word)\n",
        "print(f\"our vocab has {len(resp)} words from which we will find the ones closest to our sentence...\")\n",
        "cosine_list = [cosine(sent1_vec, model([r])[0]) for r in resp]\n",
        "vocab[\"cosine\"] = cosine_list\n",
        "vocab.nlargest(10, \"cosine\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt is: Capital of Finland\n",
            "sent1_vec is a numpy array of shape: (512,)\n",
            "our vocab has 12619 words from which we will find the ones closest to our sentence...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-14dd9aa4394d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"our vocab has {len(resp)} words from which we will find the ones closest to our sentence...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcosine_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent1_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-14dd9aa4394d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"our vocab has {len(resp)} words from which we will find the ones closest to our sentence...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcosine_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent1_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlargest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "arphJYwdjOnK",
        "outputId": "12168eda-8100-4dd6-de71-2556ce856a9d"
      },
      "source": [
        "sent1 = \"Last name of author of Little Women\"\n",
        "print(\"prompt is:\", sent1)\n",
        "sent1_vec = model([sent1])[0]\n",
        "print(\"sent1_vec is a numpy array of shape:\", sent1_vec.shape)\n",
        "resp = list(vocab.vocab_word)\n",
        "print(f\"our vocab has {len(resp)} words from which we will find the ones closest to our sentence...\")\n",
        "cosine_list = [cosine(sent1_vec, model([r])[0]) for r in resp]\n",
        "vocab[\"cosine\"] = cosine_list\n",
        "vocab.nlargest(10, \"cosine\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt is: Last name of author of Little Women\n",
            "sent1_vec is a numpy array of shape: (512,)\n",
            "our vocab has 12619 words from which we will find the ones closest to our sentence...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocab_word</th>\n",
              "      <th>cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Alcott</td>\n",
              "      <td>0.387014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>author</td>\n",
              "      <td>0.371520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11085</th>\n",
              "      <td>surname</td>\n",
              "      <td>0.349252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>Rowling</td>\n",
              "      <td>0.270690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8518</th>\n",
              "      <td>petite</td>\n",
              "      <td>0.231320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>runt</td>\n",
              "      <td>0.224465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7432</th>\n",
              "      <td>midget</td>\n",
              "      <td>0.220665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1944</th>\n",
              "      <td>biography</td>\n",
              "      <td>0.219154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12544</th>\n",
              "      <td>writer</td>\n",
              "      <td>0.217155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Austen</td>\n",
              "      <td>0.214192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      vocab_word    cosine\n",
              "41        Alcott  0.387014\n",
              "83        author  0.371520\n",
              "11085    surname  0.349252\n",
              "779      Rowling  0.270690\n",
              "8518      petite  0.231320\n",
              "780         runt  0.224465\n",
              "7432      midget  0.220665\n",
              "1944   biography  0.219154\n",
              "12544     writer  0.217155\n",
              "81        Austen  0.214192"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "Y5blPBwEj2Ti",
        "outputId": "29fcf27e-6994-40d6-c6f4-ba7afaf64dd4"
      },
      "source": [
        "sent1 = \"Instrument for performing calculations by sliding beads along rods or grooves\"\n",
        "print(\"prompt is:\", sent1)\n",
        "sent1_vec = model([sent1])[0]\n",
        "print(\"sent1_vec is a numpy array of shape:\", sent1_vec.shape)\n",
        "resp = list(vocab.vocab_word)\n",
        "print(f\"our vocab has {len(resp)} words from which we will find the ones closest to our sentence...\")\n",
        "cosine_list = [cosine(sent1_vec, model([r])[0]) for r in resp]\n",
        "vocab[\"cosine\"] = cosine_list\n",
        "vocab.nlargest(10, \"cosine\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt is: Instrument for performing calculations by sliding beads along rods or grooves\n",
            "sent1_vec is a numpy array of shape: (512,)\n",
            "our vocab has 12619 words from which we will find the ones closest to our sentence...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocab_word</th>\n",
              "      <th>cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abacus</td>\n",
              "      <td>0.361816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>calculations</td>\n",
              "      <td>0.336181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2405</th>\n",
              "      <td>calculation</td>\n",
              "      <td>0.305555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6389</th>\n",
              "      <td>instruments</td>\n",
              "      <td>0.305101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>grooves</td>\n",
              "      <td>0.302247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12417</th>\n",
              "      <td>wind instrument</td>\n",
              "      <td>0.292259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>beads</td>\n",
              "      <td>0.290021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6388</th>\n",
              "      <td>instrument</td>\n",
              "      <td>0.284906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>Instrument</td>\n",
              "      <td>0.284906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7695</th>\n",
              "      <td>musical instrument</td>\n",
              "      <td>0.276964</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               vocab_word    cosine\n",
              "2                  abacus  0.361816\n",
              "148          calculations  0.336181\n",
              "2405          calculation  0.305555\n",
              "6389          instruments  0.305101\n",
              "399               grooves  0.302247\n",
              "12417     wind instrument  0.292259\n",
              "104                 beads  0.290021\n",
              "6388           instrument  0.284906\n",
              "471            Instrument  0.284906\n",
              "7695   musical instrument  0.276964"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74M1_PAWB3w8"
      },
      "source": [
        "The Transformer based USE model is pretty accurate in and of itself, whereas the DAN is not so accurate. But we want to model a \"human\" version of this model, so we can add some stochastic noise to these estimates for both models eventually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlDMgQchCzZ9"
      },
      "source": [
        "# Create phoneme function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgMBYBZNjBIS"
      },
      "source": [
        "Here we create a function that takes any letter string and partitions it into phonemes based on arpabet. Then we compute a measure of \"normalized\" phonemic similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0phmKU8C2GW",
        "outputId": "630112d1-1c4e-438f-eeb9-d348fa91110e"
      },
      "source": [
        "# algo to obtain phonemes for any given strng\n",
        "# obtained from: https://stackoverflow.com/questions/33666557/get-phonemes-from-any-word-in-python-nltk-or-other-modules\n",
        "try:\n",
        "    arpabet = nltk.corpus.cmudict.dict()\n",
        "except LookupError:\n",
        "    nltk.download('cmudict')\n",
        "    arpabet = nltk.corpus.cmudict.dict()\n",
        "\n",
        "@lru_cache()\n",
        "def wordbreak(s):\n",
        "    s = s.lower()\n",
        "    if s in arpabet:\n",
        "        return arpabet[s]\n",
        "    middle = len(s)/2\n",
        "    partition = sorted(list(range(len(s))), key=lambda x: (x-middle)**2-x)\n",
        "    for i in partition:\n",
        "        pre, suf = (s[:i], s[i:])\n",
        "        if pre in arpabet and wordbreak(suf) is not None:\n",
        "            return [x+y for x,y in iterprod(arpabet[pre], wordbreak(suf))]\n",
        "    return None\n",
        "\n",
        "def normalized_sim(w1, w2):\n",
        "  return 1-edit_distance(w1,w2)/(max(len(w1), len(w2)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yep5HnUC7Qz",
        "outputId": "f953481e-64c0-4f55-aa23-22f9c035c91b"
      },
      "source": [
        "w1 = \"bird\"\n",
        "w2 = \"burden\"\n",
        "print(\"wordbreak(w1)[0]:\",wordbreak(w1)[0])\n",
        "print(\"wordbreak(w2)[0]:\",wordbreak(w2)[0])\n",
        "\n",
        "print(\"normalized orthographic similarity (letters):\", normalized_sim(w1, w2))\n",
        "print(\"normalized phonemic similarity:\", normalized_sim(wordbreak(w1)[0],wordbreak(w2)[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wordbreak(w1)[0]: ['B', 'ER1', 'D']\n",
            "wordbreak(w2)[0]: ['B', 'ER1', 'D', 'AH0', 'N']\n",
            "normalized orthographic similarity (letters): 0.5\n",
            "normalized phonemic similarity: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwBRDTKA7CPm"
      },
      "source": [
        "## semantic "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "725XJuMrhS0B"
      },
      "source": [
        "Below we get cosines from the prompt to the different primes and targets in our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob6NA8PgAZII",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "b93904f3-fb6b-48d3-fc8f-5bd5bc9e748f"
      },
      "source": [
        "## get cosines for:\n",
        "# 1. prompt - target\n",
        "# 2. prompt - primes\n",
        "# 3. prompt - resp\n",
        "\n",
        "both_prompt = []\n",
        "neither_prompt = []\n",
        "phon_prompt = []\n",
        "sem_prompt = []\n",
        "prime_prompt = []\n",
        "target_prompt = []\n",
        "resp_prompt = []\n",
        "\n",
        "# 4. target- primes\n",
        "target_both = []\n",
        "target_neither = []\n",
        "target_sem = []\n",
        "target_phon = []\n",
        "target_prime = []\n",
        "# 5. target - answer\n",
        "target_resp = []\n",
        "\n",
        "\n",
        "for index, row in julie_files.iterrows():\n",
        "  prompt_vec = model([row[\"prompt\"]])[0]\n",
        "  target_vec = model([row[\"Target\"]])[0]\n",
        "  resp = re.sub('[^a-zA-Z]+', '', str(row[\"Resp\"]))\n",
        "  prime = str(row[\"Prime\"])\n",
        "  #print(\"resp =\", resp)\n",
        "  \n",
        "\n",
        "  both_prompt_sim = cosine(prompt_vec, model([row[\"Both\"]])[0])\n",
        "  both_prompt.append(both_prompt_sim)\n",
        "\n",
        "  neither_prompt_sim = cosine(prompt_vec, model([row[\"Neither\"]])[0])\n",
        "  neither_prompt.append(neither_prompt_sim)\n",
        "\n",
        "  phon_prompt_sim = cosine(prompt_vec, model([row[\"Phonological\"]])[0])\n",
        "  phon_prompt.append(phon_prompt_sim)\n",
        "\n",
        "  sem_prompt_sim = cosine(prompt_vec, model([row[\"Semantic\"]])[0])\n",
        "  sem_prompt.append(sem_prompt_sim)\n",
        "\n",
        "  prime_prompt_sim = cosine(prompt_vec, model([prime])[0])\n",
        "  prime_prompt.append(prime_prompt_sim)\n",
        "\n",
        "  target_prompt_sim = cosine(prompt_vec, model([row[\"Target\"]])[0])\n",
        "  target_prompt.append(target_prompt_sim)\n",
        "  \n",
        "  resp_prompt_sim = cosine(prompt_vec, model([resp])[0]) if resp != \"\" else \"NA\"\n",
        "  resp_prompt.append(resp_prompt_sim)\n",
        "  \n",
        "\n",
        "  #4. target- primes\n",
        "  target_both_sim = cosine(target_vec, model([row[\"Both\"]])[0])\n",
        "  target_both.append(target_both_sim)\n",
        "\n",
        "  target_neither_sim = cosine(target_vec, model([row[\"Neither\"]])[0])\n",
        "  target_neither.append(target_neither_sim)\n",
        "\n",
        "  target_sem_sim = cosine(target_vec, model([row[\"Semantic\"]])[0])\n",
        "  target_sem.append(target_sem_sim)\n",
        "\n",
        "  target_phon_sim = cosine(target_vec, model([row[\"Phonological\"]])[0])\n",
        "  target_phon.append(target_phon_sim)\n",
        "\n",
        "  target_prime_sim = cosine(target_vec, model([prime])[0])\n",
        "  target_prime.append(target_prime_sim)\n",
        "\n",
        "  # 5. target - answer\n",
        "  target_resp_sim = cosine(target_vec, model([resp])[0]) if resp != \"\" else \"NA\"\n",
        "  target_resp.append(target_resp_sim)\n",
        "\n",
        "\n",
        "julie_files[\"both_prompt\"]  = both_prompt\n",
        "julie_files[\"neither_prompt\"]  = neither_prompt\n",
        "julie_files[\"sem_prompt\"]  = sem_prompt\n",
        "julie_files[\"phon_prompt\"]  = phon_prompt\n",
        "\n",
        "julie_files[\"prime_prompt\"]  = prime_prompt\n",
        "julie_files[\"target_prompt\"]  = target_prompt\n",
        "julie_files[\"resp_prompt\"]  = resp_prompt\n",
        "\n",
        "julie_files[\"target_both\"]  = target_both\n",
        "julie_files[\"target_neither\"]  = target_neither\n",
        "julie_files[\"target_sem\"]  = target_sem\n",
        "julie_files[\"target_phon\"]  = target_phon\n",
        "julie_files[\"target_prime\"]  = target_prime\n",
        "julie_files[\"target_resp\"]  = target_resp\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1cd1a7a2678c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;31m# 5. target - answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   \u001b[0mtarget_resp_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NA\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0mtarget_resp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_resp_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqUNfel34uOF"
      },
      "source": [
        "## phon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkUPd0LEha6-"
      },
      "source": [
        "Below we get estimates of phonemic similarity from the prompt to the different primes and targets in our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa1phbpr4cA2"
      },
      "source": [
        "## get normalized phonemic similarities for:\n",
        "\n",
        "# 4. target- primes\n",
        "target_both = []\n",
        "target_neither = []\n",
        "target_sem = []\n",
        "target_phon = []\n",
        "target_prime = []\n",
        "# 5. target - answer\n",
        "target_resp = []\n",
        "\n",
        "\n",
        "for index, row in julie_files.iterrows():\n",
        "  \n",
        "  resp = re.sub('[^a-zA-Z]+', '', str(row[\"Resp\"]))\n",
        "  semantic = re.sub('[^a-zA-Z]+', '', str(row[\"Semantic\"]))\n",
        "  phono = re.sub('[^a-zA-Z]+', '', str(row[\"Phonological\"]))\n",
        "  neither = re.sub('[^a-zA-Z]+', '', str(row[\"Neither\"]))\n",
        "  both = re.sub('[^a-zA-Z]+', '', str(row[\"Both\"]))\n",
        "  \n",
        "\n",
        "  prime = re.sub('[^a-zA-Z]+', '', str(row[\"Prime\"]))\n",
        "  #print(\"resp =\", resp)\n",
        "  \n",
        "\n",
        "  #4. target- primes\n",
        "  target_both_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(both)[0])\n",
        "  target_both.append(target_both_sim)\n",
        "\n",
        "  target_neither_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(neither)[0])\n",
        "  target_neither.append(target_neither_sim)\n",
        "\n",
        "  target_sem_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(semantic)[0])\n",
        "  target_sem.append(target_sem_sim)\n",
        "\n",
        "  target_phon_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(phono)[0])\n",
        "  target_phon.append(target_phon_sim)\n",
        "\n",
        "  target_prime_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(prime)[0])\n",
        "  target_prime.append(target_prime_sim)\n",
        "\n",
        "  # 5. target - answer\n",
        "  target_resp_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(resp)[0]) if resp != \"\" else \"NA\"\n",
        "  target_resp.append(target_resp_sim)\n",
        "\n",
        "julie_files[\"lev_target_both\"]  = target_both\n",
        "julie_files[\"lev_target_neither\"]  = target_neither\n",
        "julie_files[\"lev_target_sem\"]  = target_sem\n",
        "julie_files[\"lev_target_phon\"]  = target_phon\n",
        "julie_files[\"lev_target_prime\"]  = target_prime\n",
        "julie_files[\"lev_target_resp\"]  = target_resp\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRpS5r589YRv"
      },
      "source": [
        "julie_files.to_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/Julie_2021data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2rStY1ShjaX"
      },
      "source": [
        "# Modeling Ideas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_ZuyN4hhmKq"
      },
      "source": [
        "Some ways to think about how to \"model\" the task:\n",
        "\n",
        "\n",
        "1. After obtaining the representation for the prompt and all words in the vocabulary, start an \"activation\" process such that at t = 0, activation \"spreads\" from the prompt to all words in proportion to their similarity to the prompt\n",
        "2. At t=1, those words further spread activation to their neighbors.\n",
        "3. This could continue for \"t\" time steps technically, but we can also introduce a prime at some time step. This \"prime\" gets some extra boost of activation (+5 units, say), and then similarities are assessed as a combination of prompt and cue to ultimately produce the response. \n",
        "4. Maybe the ideal way to do this is an \"activation\" matrix of size vocab x 1 for both semantic and phonology and then we merge the two eventually?\n",
        "5. We may want to add in some stochastic noise to simulate partial knowledge in these models to see how that changes things\n",
        "6. So a general process model might be:\n",
        "*   activate_prompt_neighbors(noise) returns a 1-d array of similarities to every word in the vocab\n",
        "*   activate_prime_neighbors(noise) returns two N-by-1 arrays of similarities+activation corresponding to semantic and phonological similarities\n",
        "*   combine_semantic_phonological(method = \"additive | multiplicative\") returns a single N-by-1 array corresponding to combined sem-phon similarities after the promot and prime activations have been activated\n",
        "*   generate_predictions() returns a softmax of the activated matrix\n",
        "7. Ultimately, we want to make the code below efficient, and simulate about 100 participant runs with different levels of \"noise\" corresponding to levels of knowledge to obtain different model predictions\n",
        "8. Also, we may want to have a parameter that controls the weight to semantic vs. phonological information in the \"combine\" function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmvT7nTQAMD2"
      },
      "source": [
        "## preparing/reducing data size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yIQzCKOw-4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7981109b-1688-48f1-a699-5cb355894825"
      },
      "source": [
        "## preparing data\n",
        "julie_files[\"ActualPrime\"] = np.where(julie_files['PrimeCondition'] == 'P', julie_files['Phonological'], \n",
        "                                      np.where(julie_files['PrimeCondition'] == 'B', julie_files['Both'], \n",
        "                                               np.where(julie_files['PrimeCondition'] == 'R', julie_files['Semantic'],julie_files['Neither']))) \n",
        "julie_files['prompt'] = julie_files['prompt'].str.replace('\\t',' ')                                      \n",
        "julie_files['prompt'] = julie_files['prompt'].str.strip()\n",
        "print(f\"full dataset is {len(julie_files)} rows\")\n",
        "## for target accuracy we only need 100 (prompts) x 4 (primes)\n",
        "targetacc_data = julie_files[[\"ActualPrime\", \"PrimeCondition\", \"Target\", \"prompt\"]].drop_duplicates()\n",
        "targetacc_data['AddPrediction'] = np.nan\n",
        "targetacc_data['MultPrediction'] = np.nan\n",
        "print(f\"target accuracy data is {len(targetacc_data)} rows\")\n",
        "## for response accuracy we need the unique responses for each prompt-prime combination\n",
        "\n",
        "respacc_data = julie_files[[\"ActualPrime\", \"PrimeCondition\", \"Target\", \"Resp\", \"prompt\"]].drop_duplicates()\n",
        "print(f\"response accuracy data is {len(respacc_data)} rows\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "full dataset is 17400 rows\n",
            "target accuracy data is 400 rows\n",
            "response accuracy data is 4377 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIW13RMx0mZP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "outputId": "4476e53f-c81f-405a-a98f-7d5a87a3e392"
      },
      "source": [
        "## we reshape the data so that we can run the functions at the \"prompt\" level\n",
        "respacc_data = respacc_data.sort_values(by=['prompt'])\n",
        "resp_wide = respacc_data.pivot(index = [\"prompt\", \"Target\", \"Resp\"], columns = [\"PrimeCondition\"], values = [\"ActualPrime\"])\n",
        "resp_wide = resp_wide.reset_index()\n",
        "resp_wide.columns = resp_wide.columns.map('|'.join).str.strip('|')\n",
        "resp_wide = resp_wide[resp_wide.Resp != '12345']\n",
        "resp_wide = resp_wide.reset_index()\n",
        "resp_wide['AddPrediction'] = np.nan\n",
        "resp_wide['MultPrediction'] = np.nan\n",
        "resp_wide"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>prompt</th>\n",
              "      <th>Target</th>\n",
              "      <th>Resp</th>\n",
              "      <th>ActualPrime|B</th>\n",
              "      <th>ActualPrime|P</th>\n",
              "      <th>ActualPrime|R</th>\n",
              "      <th>ActualPrime|U</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20th century American poet whose trademark was...</td>\n",
              "      <td>Cummings</td>\n",
              "      <td>Browning</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Browning</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>20th century American poet whose trademark was...</td>\n",
              "      <td>Cummings</td>\n",
              "      <td>Carrol</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cummerbund</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>20th century American poet whose trademark was...</td>\n",
              "      <td>Cummings</td>\n",
              "      <td>Cummings</td>\n",
              "      <td>Cunningham</td>\n",
              "      <td>cummerbund</td>\n",
              "      <td>Browning</td>\n",
              "      <td>point</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>20th century American poet whose trademark was...</td>\n",
              "      <td>Cummings</td>\n",
              "      <td>Cunnigham</td>\n",
              "      <td>Cunningham</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>20th century American poet whose trademark was...</td>\n",
              "      <td>Cummings</td>\n",
              "      <td>Dickinson</td>\n",
              "      <td>Cunningham</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2665</th>\n",
              "      <td>2765</td>\n",
              "      <td>Word made by changing the order of letters in ...</td>\n",
              "      <td>anagram</td>\n",
              "      <td>palindrome</td>\n",
              "      <td>acronym</td>\n",
              "      <td>analytic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2666</th>\n",
              "      <td>2766</td>\n",
              "      <td>Word made by changing the order of letters in ...</td>\n",
              "      <td>anagram</td>\n",
              "      <td>plenumbra</td>\n",
              "      <td>acronym</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2667</th>\n",
              "      <td>2767</td>\n",
              "      <td>Word made by changing the order of letters in ...</td>\n",
              "      <td>anagram</td>\n",
              "      <td>puzzle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>puzzle</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2668</th>\n",
              "      <td>2768</td>\n",
              "      <td>Word made by changing the order of letters in ...</td>\n",
              "      <td>anagram</td>\n",
              "      <td>synonym</td>\n",
              "      <td>acronym</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2669</th>\n",
              "      <td>2769</td>\n",
              "      <td>Word made by changing the order of letters in ...</td>\n",
              "      <td>anagram</td>\n",
              "      <td>syntax</td>\n",
              "      <td>acronym</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2670 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  ... ActualPrime|U\n",
              "0         1  ...           NaN\n",
              "1         2  ...           NaN\n",
              "2         3  ...         point\n",
              "3         4  ...           NaN\n",
              "4         5  ...           NaN\n",
              "...     ...  ...           ...\n",
              "2665   2765  ...           NaN\n",
              "2666   2766  ...           NaN\n",
              "2667   2767  ...           NaN\n",
              "2668   2768  ...           NaN\n",
              "2669   2769  ...           NaN\n",
              "\n",
              "[2670 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxafB-c6Rl_3"
      },
      "source": [
        "# Computing all vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkIIL8nNS-0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9d39febd-0714-40e6-ac81-00b396df7367"
      },
      "source": [
        "targetacc_data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ActualPrime</th>\n",
              "      <th>PrimeCondition</th>\n",
              "      <th>Target</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>absolve</td>\n",
              "      <td>P</td>\n",
              "      <td>abstain</td>\n",
              "      <td>To refrain deliberately and often with an effo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Norderstedt</td>\n",
              "      <td>B</td>\n",
              "      <td>Nuremberg</td>\n",
              "      <td>German city for which antisemitic laws were named</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hematoma</td>\n",
              "      <td>B</td>\n",
              "      <td>hemorrhage</td>\n",
              "      <td>The escape of blood from vessels, including in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thigh</td>\n",
              "      <td>U</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Capital of South Korea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oslo</td>\n",
              "      <td>R</td>\n",
              "      <td>Helsinki</td>\n",
              "      <td>Capital of Finland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>terse</td>\n",
              "      <td>B</td>\n",
              "      <td>taciturn</td>\n",
              "      <td>Saying little, reserved, uncommunicative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>bagel</td>\n",
              "      <td>U</td>\n",
              "      <td>chameleon</td>\n",
              "      <td>A small lizard with skin that changes color to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>Sardinia</td>\n",
              "      <td>B</td>\n",
              "      <td>Sicily</td>\n",
              "      <td>The largest Mediterranean island; the Italian ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>Shelley</td>\n",
              "      <td>B</td>\n",
              "      <td>Shaw</td>\n",
              "      <td>Last name of Irish author well known for Pygma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>view</td>\n",
              "      <td>U</td>\n",
              "      <td>anachronism</td>\n",
              "      <td>Something out of keeping with the time in whic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     ActualPrime  ...                                             prompt\n",
              "0        absolve  ...  To refrain deliberately and often with an effo...\n",
              "1    Norderstedt  ...  German city for which antisemitic laws were named\n",
              "2       hematoma  ...  The escape of blood from vessels, including in...\n",
              "3          thigh  ...                             Capital of South Korea\n",
              "4           Oslo  ...                                 Capital of Finland\n",
              "..           ...  ...                                                ...\n",
              "395        terse  ...           Saying little, reserved, uncommunicative\n",
              "396        bagel  ...  A small lizard with skin that changes color to...\n",
              "397     Sardinia  ...  The largest Mediterranean island; the Italian ...\n",
              "398      Shelley  ...  Last name of Irish author well known for Pygma...\n",
              "399         view  ...  Something out of keeping with the time in whic...\n",
              "\n",
              "[400 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymrXP-Z3AQli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ea7d88f-65dc-4429-8260-b972d7ef0496"
      },
      "source": [
        "def vectors(data, vocab):\n",
        "  prompts = pd.Series(data[\"prompt\"].unique())\n",
        "  p_vecs = np.array([model([x])[0].numpy() for x in prompts])\n",
        "  print(p_vecs.shape)\n",
        "\n",
        "  p_vectors_df = pd.DataFrame(p_vecs).transpose()\n",
        "  print(p_vectors_df.shape)\n",
        "  p_vectors_df.columns = prompts\n",
        "  print(p_vectors_df.head())\n",
        "  p_vectors_df.to_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/PromptVectors_New.csv\", index = False)\n",
        "\n",
        "  words = list(vocab.vocab_word)\n",
        "  w_vecs = np.array([model([x])[0].numpy() for x in words])\n",
        "  print(w_vecs.shape)\n",
        "  w_vectors_df = pd.DataFrame(w_vecs).transpose()\n",
        "\n",
        "  print(w_vectors_df.shape)\n",
        "  w_vectors_df.columns = words\n",
        "  print(w_vectors_df.head())\n",
        "  w_vectors_df.to_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/VocabVectors_New.csv\", index = False)\n",
        "\n",
        "vectors(targetacc_data, vocab)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 512)\n",
            "(512, 100)\n",
            "   To refrain deliberately and often with an effort of self-denial from an action or practice  ...  Happening by a lucky chance or by accident rather than by design\n",
            "0                                           0.014262                                           ...                                          -0.002915               \n",
            "1                                           0.018321                                           ...                                          -0.052756               \n",
            "2                                           0.026393                                           ...                                          -0.002790               \n",
            "3                                          -0.029389                                           ...                                           0.019612               \n",
            "4                                           0.018353                                           ...                                           0.037026               \n",
            "\n",
            "[5 rows x 100 columns]\n",
            "(12619, 512)\n",
            "(512, 12619)\n",
            "          A         a    abacus  ...       zoo      zoom  zucchini\n",
            "0 -0.034784 -0.034784 -0.066512  ... -0.048157 -0.033304  0.002661\n",
            "1 -0.061211 -0.061211 -0.080752  ... -0.001644 -0.030125 -0.056137\n",
            "2  0.014873  0.014873 -0.002557  ...  0.065526 -0.006886  0.010760\n",
            "3  0.045649  0.045649  0.005688  ...  0.006332  0.052492  0.014026\n",
            "4 -0.062827 -0.062827 -0.052223  ... -0.067385 -0.049020 -0.026196\n",
            "\n",
            "[5 rows x 12619 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr8_qAO_Jb0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d134e926-96f6-4f9d-f66d-8f11d18a5c2e"
      },
      "source": [
        "prompt_vectors = pd.read_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/PromptVectors_New.csv\")\n",
        "print(prompt_vectors.shape)\n",
        "vocab_vectors = pd.read_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/VocabVectors_New.csv\")\n",
        "print(vocab_vectors.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 100)\n",
            "(512, 12619)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0tlmEPKT8eR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "6bbac15d-aacf-43f7-97a5-927bbd5f3911"
      },
      "source": [
        "vocab_vectors['finland']"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'finland'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-7e03d332e4ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'finland'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'finland'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhankmjvFTet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a3434a-f489-4095-8295-9a8ccaabfb24"
      },
      "source": [
        "#type(prompt_vectors.loc[prompt_vectors['prompt'] == 'Capital of Finland']['vector'])\n",
        "#type(vocab_vectors['vector'][1])\n",
        "#type(model(['Finland'])[0].numpy())\n",
        "#vocab_vectors.dtypes\n",
        "cosine(prompt_vectors['Capital of Finland'].values, vocab_vectors['Finland'].values)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6351254414789951"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GLm2F7xFkjF"
      },
      "source": [
        "## model functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2zZTc7w_MY6",
        "outputId": "20187e11-26ef-4113-d4f9-20c1b7401cbc"
      },
      "source": [
        "def initial_activation(vocab_words):\n",
        "  # returns an array of initial activations, currently zero, but eventually replace by word frequency\n",
        "  x = np.zeros((len(vocab_words),1)).T\n",
        "  return x\n",
        "\n",
        "initial_activation(vocab).shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 12619)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_NpIO8BF_v6"
      },
      "source": [
        "def activate_prompt_neighbors(activations, prompt, noise_level):\n",
        "  ## takes in a 1-d array of current activations\n",
        "  ## computes a vector representation of the prompt and returns a vector of similarities to each word in vocab + activations\n",
        "  ## with some noise added to each estimate\n",
        "  noise = np.random.normal(0, noise_level, 1)\n",
        "  prompt_vec = prompt_vectors[prompt].values\n",
        "  resp = vocab_vectors.columns\n",
        "  cosine_list = np.array([cosine(prompt_vec, vocab_vectors[r].values) for r in resp]) + activations # eventually add noise\n",
        "  return cosine_list\n",
        "\n",
        "#x = activate_prompt_neighbors(initial_activation(vocab), \"Capital of Finland\", 0.1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Eo-nYLGBrF"
      },
      "source": [
        "def activate_prime_neighbors(activations_sem, prime):\n",
        "  ## takes in a 1-d array of semantic activations and returns \"primed\" activations for both semantic and phonological\n",
        "  prime_vec = vocab_vectors[prime].values\n",
        "  resp = vocab_vectors.columns\n",
        "  semantic = np.array([cosine(prime_vec, vocab_vectors[r].values) for r in resp]) + activations_sem\n",
        "  phon = np.array([normalized_sim(r, prime) for r in resp]).reshape(semantic.shape)\n",
        "  assert semantic.shape == phon.shape\n",
        "  return semantic, phon\n",
        "\n",
        "#y, z = activate_prime_neighbors(x, 'Oslo')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLqfertJKXeH"
      },
      "source": [
        "def combine_semantic_phonological(semantic, phonological, method = \"multiply\", alpha=0): \n",
        "  if method == \"add\":\n",
        "    wtds = alpha * semantic\n",
        "    wtdp = (1-alpha)*phonological\n",
        "    comb = np.add(wtds, wtdp)\n",
        "  else:\n",
        "    comb = np.multiply(semantic, phonological)\n",
        "  \n",
        "  return softmax(comb)\n",
        "\n",
        "#final_activations = combine_semantic_phonological(y, z, \"add\", 0.1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI53gxtIRWgf"
      },
      "source": [
        "def generate_predictions(activations, vocab_words, topn = 10):\n",
        "  ## takes in final activations and generates the top10 predictions\n",
        "  return [list(vocab_words.vocab_word)[i] for i in np.argpartition(-activations, topn).flatten().tolist()[:topn]]\n",
        "\n",
        "#generate_predictions(final_activations, vocab, topn = 10)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS7RFXfSRzaE"
      },
      "source": [
        "def lexical_retrieval_model(prompt, prime, vocab_words, alpha):\n",
        "  ## brings all functions together\n",
        "  init = initial_activation(vocab_words)\n",
        "  x = activate_prompt_neighbors(init, vocab_words, prompt, 0.1)\n",
        "  y, z = activate_prime_neighbors(x, vocab, prime)\n",
        "  final_add = combine_semantic_phonological(y, z, \"add\", alpha)\n",
        "  final_mult = combine_semantic_phonological(y, z, \"multiply\")\n",
        "  preds_add = generate_predictions(final_add, vocab_words, topn = 10)\n",
        "  preds_mult = generate_predictions(final_mult, vocab_words, topn = 10)\n",
        "\n",
        "  return preds_add, preds_mult"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOhSccTCCeGt"
      },
      "source": [
        "## to-do\n",
        "\n",
        "1. now we should use the \"wide\" dataset above and run activate_prompt_neigbors only ONCE for each prompt \n",
        "2. so dont use the lexical_retrieval_model function but instead use the base functions (activate_prompt_neighbors etc.) by looping over the above dataset in a way that the prompt activation function is called only once and then you calculate the differnet prime activations for that same prompt activation array\n",
        "3. Let's just do this for alpha = 0.5 for now to see initial results \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmbDCGjirchl"
      },
      "source": [
        "# Response accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9xMCLZ1Ebp6"
      },
      "source": [
        "r_acc_df = pd.DataFrame(columns = ['prompt','PrimeCond', 'prime', 'alpha', 'n', 'modelType','RespAcc'])\n",
        "t_acc_df = pd.DataFrame(columns = ['prompt','PrimeCond', 'prime', 'alpha', 'n', 'modelType','TargAcc'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtrhb3jwc7h9"
      },
      "source": [
        "#add_success = []\n",
        "#mult_success = []\n",
        "#targ_add_success = []\n",
        "#targ_mult_success = []\n",
        "prompt_acts = {}\n",
        "prime_acts = {}\n",
        "def accuracy_single(t, vocab_words, n, alpha, pc):\n",
        "  # adds 1 to corresponding list if the response/target is in the top n predictions, else 0\n",
        "  #target accuracy\n",
        "  if t < len(targetacc_data.index) and pc == targetacc_data[\"PrimeCondition\"][t]: \n",
        "    if pd.isna(targetacc_data[\"AddPrediction\"][t]):\n",
        "      if targetacc_data[\"prompt\"][t] not in prompt_acts:\n",
        "        init = initial_activation(vocab_words)\n",
        "        prompt_neighbors = activate_prompt_neighbors(init, targetacc_data[\"prompt\"][t], 0.1)\n",
        "        prompt_acts[targetacc_data[\"prompt\"][t]] = prompt_neighbors\n",
        "      else:\n",
        "        prompt_neighbors = prompt_acts[targetacc_data[\"prompt\"][t]]\n",
        "\n",
        "      if targetacc_data[\"ActualPrime\"][t] not in prime_acts:\n",
        "        a, b = activate_prime_neighbors(prompt_neighbors, targetacc_data[\"ActualPrime\"][t])\n",
        "        prime_acts[targetacc_data[\"ActualPrime\"][t]] = (a, b)\n",
        "      else:\n",
        "        a, b = prime_acts[targetacc_data[\"ActualPrime\"][t]]\n",
        "      final_add = combine_semantic_phonological(a, b, \"add\", alpha)\n",
        "      final_mult = combine_semantic_phonological(a, b, \"multiply\")\n",
        "      targetacc_data[\"AddPrediction\"][t] = generate_predictions(final_add, vocab_words, 20) #if having trouble with array, join into string and then split\n",
        "      targetacc_data[\"MultPrediction\"][t] = generate_predictions(final_mult, vocab_words, 20)\n",
        "\n",
        "    success = 1 if targetacc_data[\"Target\"][t] in targetacc_data[\"AddPrediction\"][t][:n] else 0\n",
        "    pd.concat([t_acc_df, pd.DataFrame([[targetacc_data[\"prompt\"][t], pc, targetacc_data[\"ActualPrime\"][t], alpha, n, 'add', success]], columns = ['prompt','PrimeCond', 'prime', 'alpha', 'n', 'modelType','TargAcc'])], ignore_index=True)\n",
        "    success = 1 if targetacc_data[\"Target\"][t] in targetacc_data[\"MultPrediction\"][t][:n] else 0\n",
        "    pd.concat([t_acc_df, pd.DataFrame([[targetacc_data[\"prompt\"][t], pc, targetacc_data[\"ActualPrime\"][t], alpha, n, 'mult', success]], columns = ['prompt','PrimeCond', 'prime', 'alpha', 'n', 'modelType','TargAcc'])], ignore_index=True)\n",
        "\n",
        "  #response accuracy\n",
        "  col = \"ActualPrime|\" + pc\n",
        "  if  pd.notna(resp_wide[col][t]):\n",
        "    if pd.isna(resp_wide[\"AddPrediction\"][t]):\n",
        "      if resp_wide[\"prompt\"][t] not in prompt_acts:\n",
        "        init = initial_activation(vocab_words)\n",
        "        prompt_neighbors = activate_prompt_neighbors(init, resp_wide[\"prompt\"][t], 0.1)\n",
        "        prompt_acts[resp_wide[\"prompt\"][t]] = prompt_neighbors\n",
        "      else:\n",
        "        prompt_neighbors = prompt_acts[resp_wide[\"prompt\"][t]]\n",
        "      \n",
        "      if resp_wide[col][t] not in prime_acts:\n",
        "        a, b = activate_prime_neighbors(prompt_neighbors, resp_wide[col][t])\n",
        "        prime_acts[resp_wide[col][t]] = (a, b)\n",
        "      else:\n",
        "        a, b = prime_acts[resp_wide[col][t]]\n",
        "        \n",
        "      final_add = combine_semantic_phonological(a, b, \"add\", alpha)\n",
        "      final_mult = combine_semantic_phonological(a, b, \"multiply\")\n",
        "      resp_wide[\"AddPrediction\"][t] = generate_predictions(final_add, vocab_words, 20)\n",
        "      resp_wide[\"MultPrediction\"][t] = generate_predictions(final_mult, vocab_words, 20)\n",
        "\n",
        "    success = 1 if resp_wide[\"Resp\"][t].lower() in (pred.lower() for pred in resp_wide[\"AddPrediction\"][t][:n]) else 0\n",
        "    pd.concat([r_acc_df, pd.DataFrame([[resp_wide[\"prompt\"][t], pc, resp_wide[col][t], alpha, n, 'add', success]], columns = ['prompt','PrimeCond', 'prime', 'alpha', 'n', 'modelType','RespAcc'])], ignore_index=True)\n",
        "    success = 1 if resp_wide[\"Resp\"][t].lower() in (pred.lower() for pred in resp_wide[\"MultPrediction\"][t][:n]) else 0\n",
        "    pd.concat([r_acc_df, pd.DataFrame([[resp_wide[\"prompt\"][t], pc, resp_wide[col][t], alpha, n, 'mult', success]], columns = ['prompt','PrimeCond', 'prime', 'alpha', 'n', 'modelType','RespAcc'])], ignore_index=True)\n",
        "\n",
        "def accuracy_overall(vocab_words, n, alpha, pc):\n",
        "  # returns the overall probability that the response will appear in the top n words predicted by the model\n",
        "  add_success.clear()\n",
        "  mult_success.clear()\n",
        "  targ_add_success.clear()\n",
        "  targ_mult_success.clear()\n",
        "  for t in range(len(resp_wide.index)):\n",
        "    accuracy_single(t, vocab_words, n, alpha, pc)\n",
        "  r_acc_add = np.mean(add_success)\n",
        "  r_acc_mult = np.mean(mult_success)\n",
        "  t_acc_add = np.mean(targ_add_success)\n",
        "  t_acc_mult = np.mean(targ_mult_success)\n",
        "  pd.concat([acc_df, pd.DataFrame([[alpha, n, pc, r_acc_add, r_acc_mult, t_acc_add, t_acc_mult]], columns = ['alpha', 'n', 'PrimeCond', 'RAddAccuracy', 'RMultAccuracy', 'TAddAccuracy', 'TMultAccuracy'])], ignore_index=True)\n",
        "  #return r_acc_add, r_acc_mult, t_acc_add, t_acc_mult"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOjgC6VUHiiw",
        "outputId": "4e26e1b8-e5ed-4dd7-96a2-87fc1e3664de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create dataframe of response & target accuracies for all alpha values, n 1-20, for each prime condition, \n",
        "# for additive and multiplicative model\n",
        "alpha = [x * 0.1 for x in range(11)]\n",
        "nums = range(1,21)\n",
        "pc = ['B', 'P', 'R', 'U']\n",
        "for p in pc:\n",
        "  for a in alpha[:3]:\n",
        "      for n in nums:\n",
        "      accuracy_overall(vocab, n, a, p)\n",
        "  print(\"Completed with alpha\", a)\n",
        "\n",
        "acc_df.to_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/Accuracy.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed with alpha 0.0\n",
            "Completed with alpha 0.1\n",
            "Completed with alpha 0.2\n",
            "Completed with alpha 0.30000000000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeX3q7ai-H5O"
      },
      "source": [
        "acc_df = pd.read_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/Accuracy.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSwEmQsCk582"
      },
      "source": [
        "for p in pc:\n",
        "  for a in alpha[3:7]:\n",
        "      for n in nums:\n",
        "      accuracy_overall(vocab, n, a, p)\n",
        "  print(\"Completed with alpha\", a)\n",
        "\n",
        "acc_df.to_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/Accuracy.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7PEWsIA-Nmz"
      },
      "source": [
        "acc_df = pd.read_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/Accuracy.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpUnygqoOVOz"
      },
      "source": [
        "for p in pc:\n",
        "  for a in alpha[7:]:\n",
        "      for n in nums:\n",
        "      accuracy_overall(vocab, n, a, p)\n",
        "  print(\"Completed with alpha\", a)\n",
        "\n",
        "acc_df.to_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/Accuracy.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aho5VDjnlwAV"
      },
      "source": [
        "participant_acc = julie_files[\"NewAccuracy\"].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "vgYJcF64Wnrd",
        "outputId": "6ee8d924-ec33-459f-d599-23ba4009c07b"
      },
      "source": [
        "# plot response and target accuracy together with varying n's, alpha = .8\n",
        "rAdd = []\n",
        "rMult = []\n",
        "tAdd = []\n",
        "tMult = []\n",
        "x = range(1,21)\n",
        "for i in x:\n",
        "  acc = accuracy_overall(vocab, i, 0.8)\n",
        "  rAdd.append(acc[0])\n",
        "  rMult.append(acc[1])\n",
        "  tAdd.append(acc[2])\n",
        "  tMult.append(acc[3])\n",
        "  print(\"Completed with n\", i)\n",
        "\n",
        "plt.plot(x, rAdd, 'r--', x, rMult, 'rs', x, tAdd, 'b--', x, tMult, 'bs')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed with n 1\n",
            "Completed with n 2\n",
            "Completed with n 3\n",
            "Completed with n 4\n",
            "Completed with n 5\n",
            "Completed with n 6\n",
            "Completed with n 7\n",
            "Completed with n 8\n",
            "Completed with n 9\n",
            "Completed with n 10\n",
            "Completed with n 11\n",
            "Completed with n 12\n",
            "Completed with n 13\n",
            "Completed with n 14\n",
            "Completed with n 15\n",
            "Completed with n 16\n",
            "Completed with n 17\n",
            "Completed with n 18\n",
            "Completed with n 19\n",
            "Completed with n 20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3b554f9e90>,\n",
              " <matplotlib.lines.Line2D at 0x7f3b555090d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f3b555092d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f3b55509550>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "EOHecn9lnhc1",
        "outputId": "2ba55da3-4bd0-4d5a-dc79-f0a3f0453629"
      },
      "source": [
        "plt.plot(x, rAdd, 'r--', x, rMult, 'rs', x, tAdd, 'b--', x, tMult, 'bs')\n",
        "plt.xlabel(\"Top N Predictions\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dovHmQAiwoT6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "outputId": "7f0e11db-14fa-4dcb-f59c-4e886c6fcbe2"
      },
      "source": [
        "# plot accuracy as a function of n or alpha for both add and mult \n",
        "#nvals = [i for i in range(5, 11)] #change upper bound depending on value of topn used in generate_predictions()\n",
        "#plt.plot(nvals, accuracy_overall(vocab, nvals)[0], 'r--', nvals, accuracy_overall(vocab, nvals)[1]) \n",
        "a = [x * 0.1 for x in range(11)]\n",
        "yAdd = []\n",
        "yMult = []\n",
        "for i in a:\n",
        "  acc = accuracy_overall(vocab, 10, i, resp_wide)\n",
        "  yAdd.append(acc[0])\n",
        "  yMult.append(acc[1])\n",
        "  print(\"Completed with alpha\", i)\n",
        "\n",
        "plt.plot(a, yAdd, 'r--', a, yMult, 'bs')\n",
        "plt.show()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of additive model: 0.07744531053557958\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 0.0\n",
            "Accuracy of additive model: 0.08901181795323108\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 0.1\n",
            "Accuracy of additive model: 0.09504651747548404\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 0.2\n",
            "Accuracy of additive model: 0.10611013326628112\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 0.30000000000000004\n",
            "Accuracy of additive model: 0.1249685692733216\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 0.4\n",
            "Accuracy of additive model: 0.14382700528036207\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 0.5\n",
            "Accuracy of additive model: 0.16117676640683934\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 0.6000000000000001\n",
            "Accuracy of additive model: 0.17374905707819965\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 0.7000000000000001\n",
            "Accuracy of additive model: 0.18028664822730703\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 0.8\n",
            "Accuracy of additive model: 0.17475484033190847\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 0.9\n",
            "Accuracy of additive model: 0.1719889363842092\n",
            "Accuracy of multiplicative model: 0.12195121951219512\n",
            "Completed with alpha 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHIaihrFTsDQ"
      },
      "source": [
        "# Measure target accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "LPuXW-tmt0D2",
        "outputId": "ab125d5d-14b2-4ece-cdfd-4d9be688666d"
      },
      "source": [
        "targetacc_data"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ActualPrime</th>\n",
              "      <th>PrimeCondition</th>\n",
              "      <th>Target</th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>absolve</td>\n",
              "      <td>P</td>\n",
              "      <td>abstain</td>\n",
              "      <td>To refrain deliberately and often with an effo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Norderstedt</td>\n",
              "      <td>B</td>\n",
              "      <td>Nuremberg</td>\n",
              "      <td>German city for which antisemitic laws were named</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hematoma</td>\n",
              "      <td>B</td>\n",
              "      <td>hemorrhage</td>\n",
              "      <td>The escape of blood from vessels, including in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>thigh</td>\n",
              "      <td>U</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Capital of South Korea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oslo</td>\n",
              "      <td>R</td>\n",
              "      <td>Helsinki</td>\n",
              "      <td>Capital of Finland</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>terse</td>\n",
              "      <td>B</td>\n",
              "      <td>taciturn</td>\n",
              "      <td>Saying little, reserved, uncommunicative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>bagel</td>\n",
              "      <td>U</td>\n",
              "      <td>chameleon</td>\n",
              "      <td>A small lizard with skin that changes color to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>Sardinia</td>\n",
              "      <td>B</td>\n",
              "      <td>Sicily</td>\n",
              "      <td>The largest Mediterranean island; the Italian ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>Shelley</td>\n",
              "      <td>B</td>\n",
              "      <td>Shaw</td>\n",
              "      <td>Last name of Irish author well known for Pygma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>view</td>\n",
              "      <td>U</td>\n",
              "      <td>anachronism</td>\n",
              "      <td>Something out of keeping with the time in whic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     ActualPrime  ...                                             prompt\n",
              "0        absolve  ...  To refrain deliberately and often with an effo...\n",
              "1    Norderstedt  ...  German city for which antisemitic laws were named\n",
              "2       hematoma  ...  The escape of blood from vessels, including in...\n",
              "3          thigh  ...                             Capital of South Korea\n",
              "4           Oslo  ...                                 Capital of Finland\n",
              "..           ...  ...                                                ...\n",
              "395        terse  ...           Saying little, reserved, uncommunicative\n",
              "396        bagel  ...  A small lizard with skin that changes color to...\n",
              "397     Sardinia  ...  The largest Mediterranean island; the Italian ...\n",
              "398      Shelley  ...  Last name of Irish author well known for Pygma...\n",
              "399         view  ...  Something out of keeping with the time in whic...\n",
              "\n",
              "[400 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZuAfyBstAGw"
      },
      "source": [
        "saved_prompt_acts = prompt_acts\n",
        "saved_prime_acts = prime_acts"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7czHT5ZmHSC"
      },
      "source": [
        "# modify functions for targetacc_data\n",
        "targ_add_success = []\n",
        "targ_mult_success = []\n",
        "def targ_acc_single(t, vocab_words, n, alpha, data):\n",
        "  prompt_neighbors = saved_prompt_acts[data[\"prompt\"][t]]\n",
        "  if data[\"ActualPrime\"][t] not in saved_prime_acts:\n",
        "    a, b = activate_prime_neighbors(prompt_neighbors, data[\"ActualPrime\"][t])\n",
        "    saved_prime_acts[data[\"ActualPrime\"][t]] = (a, b)\n",
        "  else:\n",
        "    a, b = saved_prime_acts[data[\"ActualPrime\"][t]]\n",
        "  final_add = combine_semantic_phonological(a, b, \"add\", alpha)\n",
        "  final_mult = combine_semantic_phonological(a, b, \"multiply\")\n",
        "  preds_add = generate_predictions(final_add, vocab_words, topn = 10)\n",
        "  preds_mult = generate_predictions(final_mult, vocab_words, topn = 10)\n",
        "  if data[\"Target\"][t] in preds_add[:n]:\n",
        "    targ_add_success.append(1)\n",
        "  else:\n",
        "    targ_add_success.append(0)\n",
        "  if data[\"Target\"][t] in preds_mult[:n]:\n",
        "    targ_mult_success.append(1)\n",
        "  else:\n",
        "    targ_mult_success.append(0)\n",
        "\n",
        "def targ_acc_overall(vocab_words, n, alpha, data):\n",
        "  # returns the overall probability that the target will appear in the top n words predicted by the model\n",
        "  targ_add_success.clear()\n",
        "  targ_mult_success.clear()\n",
        "  for t in range(len(data.index)):\n",
        "    targ_acc_single(t, vocab_words, n, alpha, data)\n",
        "  acc_add = np.mean(targ_add_success)\n",
        "  acc_mult = np.mean(targ_mult_success)\n",
        "  print(\"Accuracy of additive model:\", acc_add)\n",
        "  print(\"Accuracy of multiplicative model:\", acc_mult)\n",
        "  return acc_add, acc_mult"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "946ws6lazGly",
        "outputId": "b273cdc8-b8db-4642-8c64-80aa495f2cbd"
      },
      "source": [
        "targAdd = []\n",
        "targMult = []\n",
        "for i in a:\n",
        "  acc = targ_acc_overall(vocab, 10, i, targetacc_data)\n",
        "  targAdd.append(acc[0])\n",
        "  targMult.append(acc[1])\n",
        "  print(\"Completed with alpha\", i)\n",
        "\n",
        "plt.plot(a, targAdd, 'r--', a, targMult, 'bs')\n",
        "plt.show()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of additive model: 0.0825\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 0.0\n",
            "Accuracy of additive model: 0.1375\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 0.1\n",
            "Accuracy of additive model: 0.1725\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 0.2\n",
            "Accuracy of additive model: 0.23\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 0.30000000000000004\n",
            "Accuracy of additive model: 0.2925\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 0.4\n",
            "Accuracy of additive model: 0.355\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 0.5\n",
            "Accuracy of additive model: 0.4075\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 0.6000000000000001\n",
            "Accuracy of additive model: 0.44\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 0.7000000000000001\n",
            "Accuracy of additive model: 0.4425\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 0.8\n",
            "Accuracy of additive model: 0.41\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 0.9\n",
            "Accuracy of additive model: 0.385\n",
            "Accuracy of multiplicative model: 0.2825\n",
            "Completed with alpha 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsvnz-YWJR17"
      },
      "source": [
        "More plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "l6bnahpKIyKM",
        "outputId": "28a6feaa-fb14-4357-b935-cffe44b7d5a7"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3aacb59d0f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myAdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myMult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargAdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargMult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOLXKbovY4U7"
      },
      "source": [
        "# model predictions: examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sskbdFgUTPPT",
        "outputId": "3d41f1e8-cee0-4869-fe05-8aec50ea818a"
      },
      "source": [
        "add, mult = lexical_retrieval_model(\"Capital of Finland\", \"Helsinki\", vocab)\n",
        "print(\"predictions for additive model:\", add)\n",
        "print(\"predictions for multiplicative model:\", mult)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predictions for additive model: ['Helsinki', 'Finland', 'Czechoslovakia', 'Oslo', 'Nordic', 'Sweden', 'Berlin', 'Holland', 'Iceland', 'Celtic']\n",
            "predictions for multiplicative model: ['Holland', 'Czechoslovakia', 'Berlin', 'Celtic', 'Helsinki', 'ski', 'Alpine', 'herring', 'Pilsen', 'clingy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4aWABnETWbk",
        "outputId": "93fa0ab7-aec8-45d1-f41f-93f86cb47676"
      },
      "source": [
        "add, mult = lexical_retrieval_model(\"A mathematical expression consisting of two terms\", \"bilateral\", vocab)\n",
        "print(\"predictions for additive model:\", add)\n",
        "print(\"predictions for multiplicative model:\", mult)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predictions for additive model: ['biannual', 'bilateral', 'integral', 'mathematical', 'bisexual', 'partial', 'paternal', 'interval', 'binomial', 'mutual']\n",
            "predictions for multiplicative model: ['bilateral', 'biannual', 'integral', 'binomial', 'paternal', 'interval', 'bisexual', 'partial', 'plural', 'mathematical']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiGUMx5ZWhvp",
        "outputId": "5bafc958-b52e-4ee5-c8bc-56d98b914039"
      },
      "source": [
        "add, mult = lexical_retrieval_model(\"Identical in form; coinciding exactly when superimposed\", \"cognizant\", vocab)\n",
        "print(\"predictions for additive model:\", add)\n",
        "print(\"predictions for multiplicative model:\", mult)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predictions for additive model: ['constant', 'cognition', 'cognizant', 'cognitive', 'confidant', 'confident', 'congruent', 'ignorant', 'coinciding', 'recognition']\n",
            "predictions for multiplicative model: ['cognition', 'cognizant', 'cognitive', 'confident', 'confidant', 'constant', 'recognition', 'ignorant', 'coinciding', 'congruent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZGs7LTRXjFZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}