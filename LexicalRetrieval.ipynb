{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LexicalRetrieval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhilasha-kumar/modeling-lexical-retrieval/blob/main/LexicalRetrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkUSyf_WeMwt"
      },
      "source": [
        "# Allow drive access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bFV9y2TXkgz",
        "outputId": "5072c781-1899-4034-a1e3-04d09d7a5a7d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53eYB-A0eP98"
      },
      "source": [
        "# GPU access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2HxbC0YYEkR",
        "outputId": "09e90fe0-f558-4c73-8a36-0c7b4ec783f3"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Mon Oct 25 03:07:55 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    65W / 149W |    121MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cmvK8BJ8SV5"
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import heapq\n",
        "import itertools\n",
        "import scipy.spatial.distance\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from numpy.random import randint\n",
        "from scipy.special import softmax\n",
        "from sklearn.preprocessing import MinMaxScaler, normalize\n",
        "from numpy.linalg import matrix_power\n",
        "from functools import lru_cache\n",
        "import glob\n",
        "from scipy.special import expit\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from functools import lru_cache\n",
        "from itertools import product as iterprod\n",
        "import itertools\n",
        "from nltk.metrics import *\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgV7A0mY8v2s"
      },
      "source": [
        "# Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gycn2xZ08Ul2",
        "outputId": "23bf6393-4c62-4ac7-b07e-b42db6cf7da2"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  julie_files = pd.read_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/Julie_2021data.csv\", encoding= 'unicode_escape')\n",
        "  vocab = pd.read_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/julie_vocab.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "bBtAAkWcB25V",
        "outputId": "03a88594-ccc4-4c2e-84ca-699a2c1d22c4"
      },
      "source": [
        "julie_files.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>StudyNo</th>\n",
              "      <th>AgeGroup</th>\n",
              "      <th>PrimeInstruction</th>\n",
              "      <th>ExperimentName</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Procedure</th>\n",
              "      <th>Trial</th>\n",
              "      <th>Both</th>\n",
              "      <th>Neither</th>\n",
              "      <th>Phonological</th>\n",
              "      <th>Semantic</th>\n",
              "      <th>Prime</th>\n",
              "      <th>PrimeCondition</th>\n",
              "      <th>Question.RESP</th>\n",
              "      <th>State.RT</th>\n",
              "      <th>FreeResp</th>\n",
              "      <th>Resp</th>\n",
              "      <th>FreeResp.RT</th>\n",
              "      <th>NewAccuracy</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>FreeRespPrimeIntrusion</th>\n",
              "      <th>Target</th>\n",
              "      <th>MCCorrect</th>\n",
              "      <th>McResp</th>\n",
              "      <th>McAcc</th>\n",
              "      <th>McRT</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>McActualResp</th>\n",
              "      <th>WhichPrime</th>\n",
              "      <th>ToEliminate</th>\n",
              "      <th>prompt</th>\n",
              "      <th>both_prompt</th>\n",
              "      <th>neither_prompt</th>\n",
              "      <th>sem_prompt</th>\n",
              "      <th>phon_prompt</th>\n",
              "      <th>prime_prompt</th>\n",
              "      <th>target_prompt</th>\n",
              "      <th>resp_prompt</th>\n",
              "      <th>target_both</th>\n",
              "      <th>target_neither</th>\n",
              "      <th>target_sem</th>\n",
              "      <th>target_phon</th>\n",
              "      <th>target_prime</th>\n",
              "      <th>target_resp</th>\n",
              "      <th>lev_target_both</th>\n",
              "      <th>lev_target_neither</th>\n",
              "      <th>lev_target_sem</th>\n",
              "      <th>lev_target_phon</th>\n",
              "      <th>lev_target_prime</th>\n",
              "      <th>lev_target_resp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>Old</td>\n",
              "      <td>NotThePrime</td>\n",
              "      <td>tot not the prime</td>\n",
              "      <td>701</td>\n",
              "      <td>ExpProc1</td>\n",
              "      <td>1</td>\n",
              "      <td>avoid</td>\n",
              "      <td>dove</td>\n",
              "      <td>absolve</td>\n",
              "      <td>refuse</td>\n",
              "      <td>ABSOLVE</td>\n",
              "      <td>P</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12345</td>\n",
              "      <td>1527</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>abstain</td>\n",
              "      <td>c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>refuse</td>\n",
              "      <td>dove</td>\n",
              "      <td>abstain</td>\n",
              "      <td>absolve</td>\n",
              "      <td>avoid</td>\n",
              "      <td>0</td>\n",
              "      <td>X</td>\n",
              "      <td>0</td>\n",
              "      <td>To refrain deliberately and often with an effo...</td>\n",
              "      <td>0.066920</td>\n",
              "      <td>-0.033121</td>\n",
              "      <td>0.171530</td>\n",
              "      <td>0.127612</td>\n",
              "      <td>0.127612</td>\n",
              "      <td>0.125816</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.312840</td>\n",
              "      <td>0.089485</td>\n",
              "      <td>0.464569</td>\n",
              "      <td>0.217932</td>\n",
              "      <td>0.217932</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>Old</td>\n",
              "      <td>NotThePrime</td>\n",
              "      <td>tot not the prime</td>\n",
              "      <td>701</td>\n",
              "      <td>ExpProc1</td>\n",
              "      <td>2</td>\n",
              "      <td>Norderstedt</td>\n",
              "      <td>image</td>\n",
              "      <td>neurosurgery</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>NORDERSTEDT</td>\n",
              "      <td>B</td>\n",
              "      <td>2</td>\n",
              "      <td>6947</td>\n",
              "      <td>0</td>\n",
              "      <td>12345</td>\n",
              "      <td>1060</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nuremberg</td>\n",
              "      <td>d</td>\n",
              "      <td>d</td>\n",
              "      <td>1</td>\n",
              "      <td>7385</td>\n",
              "      <td>Norderstedt</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>image</td>\n",
              "      <td>Nuremberg</td>\n",
              "      <td>neurosurgery</td>\n",
              "      <td>Nuremberg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>German city for which antisemitic laws were na...</td>\n",
              "      <td>0.020833</td>\n",
              "      <td>-0.096533</td>\n",
              "      <td>0.164941</td>\n",
              "      <td>0.021730</td>\n",
              "      <td>0.020833</td>\n",
              "      <td>0.225719</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.180054</td>\n",
              "      <td>0.007681</td>\n",
              "      <td>0.428896</td>\n",
              "      <td>0.328091</td>\n",
              "      <td>0.180054</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Old</td>\n",
              "      <td>NotThePrime</td>\n",
              "      <td>tot not the prime</td>\n",
              "      <td>701</td>\n",
              "      <td>ExpProc1</td>\n",
              "      <td>3</td>\n",
              "      <td>hematoma</td>\n",
              "      <td>window</td>\n",
              "      <td>homeowner</td>\n",
              "      <td>contusion</td>\n",
              "      <td>HEMATOMA</td>\n",
              "      <td>B</td>\n",
              "      <td>4</td>\n",
              "      <td>5920</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12345</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hemorrhage</td>\n",
              "      <td>d</td>\n",
              "      <td>d</td>\n",
              "      <td>1</td>\n",
              "      <td>5430</td>\n",
              "      <td>hematoma</td>\n",
              "      <td>contusion</td>\n",
              "      <td>window</td>\n",
              "      <td>hemorrhage</td>\n",
              "      <td>homeowner</td>\n",
              "      <td>hemorrhage</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>The escape of blood from vessels, including in...</td>\n",
              "      <td>0.155783</td>\n",
              "      <td>0.027197</td>\n",
              "      <td>0.066568</td>\n",
              "      <td>-0.063326</td>\n",
              "      <td>0.155783</td>\n",
              "      <td>0.326574</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.653506</td>\n",
              "      <td>0.210072</td>\n",
              "      <td>0.458587</td>\n",
              "      <td>0.151632</td>\n",
              "      <td>0.653506</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Old</td>\n",
              "      <td>NotThePrime</td>\n",
              "      <td>tot not the prime</td>\n",
              "      <td>701</td>\n",
              "      <td>ExpProc1</td>\n",
              "      <td>4</td>\n",
              "      <td>Saigon</td>\n",
              "      <td>thigh</td>\n",
              "      <td>sofa</td>\n",
              "      <td>Tokyo</td>\n",
              "      <td>THIGH</td>\n",
              "      <td>U</td>\n",
              "      <td>1</td>\n",
              "      <td>4833</td>\n",
              "      <td>seoul</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>3272</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>b</td>\n",
              "      <td>b</td>\n",
              "      <td>1</td>\n",
              "      <td>4168</td>\n",
              "      <td>sofa</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>Saigon</td>\n",
              "      <td>thigh</td>\n",
              "      <td>Tokyo</td>\n",
              "      <td>Seoul</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Capital of South Korea</td>\n",
              "      <td>0.270083</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.378604</td>\n",
              "      <td>0.100953</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.609253</td>\n",
              "      <td>0.609253</td>\n",
              "      <td>0.424191</td>\n",
              "      <td>0.144735</td>\n",
              "      <td>0.464015</td>\n",
              "      <td>0.166060</td>\n",
              "      <td>0.144735</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>Old</td>\n",
              "      <td>NotThePrime</td>\n",
              "      <td>tot not the prime</td>\n",
              "      <td>701</td>\n",
              "      <td>ExpProc1</td>\n",
              "      <td>5</td>\n",
              "      <td>Heinola</td>\n",
              "      <td>shop</td>\n",
              "      <td>handkerchief</td>\n",
              "      <td>Oslo</td>\n",
              "      <td>OSLO</td>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>7553</td>\n",
              "      <td>helsinki</td>\n",
              "      <td>Helsinki</td>\n",
              "      <td>3497</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Helsinki</td>\n",
              "      <td>d</td>\n",
              "      <td>d</td>\n",
              "      <td>1</td>\n",
              "      <td>3366</td>\n",
              "      <td>Heinola</td>\n",
              "      <td>Oslo</td>\n",
              "      <td>shop</td>\n",
              "      <td>Helsinki</td>\n",
              "      <td>handkerchief</td>\n",
              "      <td>Helsinki</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Capital of Finland</td>\n",
              "      <td>0.034701</td>\n",
              "      <td>-0.015010</td>\n",
              "      <td>0.383043</td>\n",
              "      <td>-0.002959</td>\n",
              "      <td>0.383043</td>\n",
              "      <td>0.575294</td>\n",
              "      <td>0.575294</td>\n",
              "      <td>0.222391</td>\n",
              "      <td>0.110593</td>\n",
              "      <td>0.546045</td>\n",
              "      <td>0.080330</td>\n",
              "      <td>0.546045</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ...  lev_target_prime lev_target_resp\n",
              "0           0             0  ...          0.333333             NaN\n",
              "1           1             1  ...          0.142857             NaN\n",
              "2           2             2  ...          0.375000             NaN\n",
              "3           3             3  ...          0.000000             1.0\n",
              "4           4             4  ...          0.125000             1.0\n",
              "\n",
              "[5 rows x 56 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzBs_-3G85P2"
      },
      "source": [
        "# Import USE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y29lkvMWebIT"
      },
      "source": [
        "The Universal Sentence Encoder uses two different architctures to encode a string of any length into a compact high-dimensional vector representation -- the Deep Averaging Network (which is more of a bag-of-words approach) and the Transformer network (more predictive, attention-based). See link above for more details -- but DAN is generally faster and slightly less accurate than the Transformer model on NLP tasks (we might want to compare both). Below we see some examples of how we can use these \"vectors\" to find \"closest neighbors\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyMKr_vB8hck",
        "outputId": "c185ffe1-98f8-440e-b72a-a52510746e40"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "dan_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "#transformer_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\" \n",
        "model = hub.load(dan_url)\n",
        "print (\"module %s loaded\" % dan_url)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9DrYP8S61Qq",
        "outputId": "e7da2135-cd70-4ff3-9879-66ac3db22fab"
      },
      "source": [
        "model([\"apple\"])[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0MFBFD1eaTl"
      },
      "source": [
        "def cosine(u, v):\n",
        "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "nIa2gruXfg2F",
        "outputId": "f6971d28-cac5-4848-bc9b-53628b930499"
      },
      "source": [
        "sent1 = \"Capital of Finland\"\n",
        "print(\"prompt is:\", sent1)\n",
        "sent1_vec = model([sent1])[0]\n",
        "print(\"sent1_vec is a numpy array of shape:\", sent1_vec.shape)\n",
        "resp = list(vocab.vocab_word)\n",
        "print(f\"our vocab has {len(resp)} words from which we will find the ones closest to our sentence...\")\n",
        "cosine_list = [cosine(sent1_vec, model([r])[0]) for r in resp]\n",
        "vocab[\"cosine\"] = cosine_list\n",
        "vocab.nlargest(10, \"cosine\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt is: Capital of Finland\n",
            "sent1_vec is a numpy array of shape: (512,)\n",
            "our vocab has 12619 words from which we will find the ones closest to our sentence...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocab_word</th>\n",
              "      <th>cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>Finland</td>\n",
              "      <td>0.691257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>Helsinki</td>\n",
              "      <td>0.679515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>Capital</td>\n",
              "      <td>0.489831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2461</th>\n",
              "      <td>capital</td>\n",
              "      <td>0.489831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2464</th>\n",
              "      <td>capitol</td>\n",
              "      <td>0.472787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>Sweden</td>\n",
              "      <td>0.434951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>Berlin</td>\n",
              "      <td>0.396807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7892</th>\n",
              "      <td>Nordic</td>\n",
              "      <td>0.392326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7899</th>\n",
              "      <td>Norway</td>\n",
              "      <td>0.387974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>640</th>\n",
              "      <td>Oslo</td>\n",
              "      <td>0.383584</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     vocab_word    cosine\n",
              "347     Finland  0.691257\n",
              "421    Helsinki  0.679515\n",
              "157     Capital  0.489831\n",
              "2461    capital  0.489831\n",
              "2464    capitol  0.472787\n",
              "861      Sweden  0.434951\n",
              "113      Berlin  0.396807\n",
              "7892     Nordic  0.392326\n",
              "7899     Norway  0.387974\n",
              "640        Oslo  0.383584"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "arphJYwdjOnK",
        "outputId": "12168eda-8100-4dd6-de71-2556ce856a9d"
      },
      "source": [
        "sent1 = \"Last name of author of Little Women\"\n",
        "print(\"prompt is:\", sent1)\n",
        "sent1_vec = model([sent1])[0]\n",
        "print(\"sent1_vec is a numpy array of shape:\", sent1_vec.shape)\n",
        "resp = list(vocab.vocab_word)\n",
        "print(f\"our vocab has {len(resp)} words from which we will find the ones closest to our sentence...\")\n",
        "cosine_list = [cosine(sent1_vec, model([r])[0]) for r in resp]\n",
        "vocab[\"cosine\"] = cosine_list\n",
        "vocab.nlargest(10, \"cosine\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt is: Last name of author of Little Women\n",
            "sent1_vec is a numpy array of shape: (512,)\n",
            "our vocab has 12619 words from which we will find the ones closest to our sentence...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocab_word</th>\n",
              "      <th>cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Alcott</td>\n",
              "      <td>0.387014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>author</td>\n",
              "      <td>0.371520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11085</th>\n",
              "      <td>surname</td>\n",
              "      <td>0.349252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>779</th>\n",
              "      <td>Rowling</td>\n",
              "      <td>0.270690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8518</th>\n",
              "      <td>petite</td>\n",
              "      <td>0.231320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>780</th>\n",
              "      <td>runt</td>\n",
              "      <td>0.224465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7432</th>\n",
              "      <td>midget</td>\n",
              "      <td>0.220665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1944</th>\n",
              "      <td>biography</td>\n",
              "      <td>0.219154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12544</th>\n",
              "      <td>writer</td>\n",
              "      <td>0.217155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Austen</td>\n",
              "      <td>0.214192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      vocab_word    cosine\n",
              "41        Alcott  0.387014\n",
              "83        author  0.371520\n",
              "11085    surname  0.349252\n",
              "779      Rowling  0.270690\n",
              "8518      petite  0.231320\n",
              "780         runt  0.224465\n",
              "7432      midget  0.220665\n",
              "1944   biography  0.219154\n",
              "12544     writer  0.217155\n",
              "81        Austen  0.214192"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "Y5blPBwEj2Ti",
        "outputId": "29fcf27e-6994-40d6-c6f4-ba7afaf64dd4"
      },
      "source": [
        "sent1 = \"Instrument for performing calculations by sliding beads along rods or grooves\"\n",
        "print(\"prompt is:\", sent1)\n",
        "sent1_vec = model([sent1])[0]\n",
        "print(\"sent1_vec is a numpy array of shape:\", sent1_vec.shape)\n",
        "resp = list(vocab.vocab_word)\n",
        "print(f\"our vocab has {len(resp)} words from which we will find the ones closest to our sentence...\")\n",
        "cosine_list = [cosine(sent1_vec, model([r])[0]) for r in resp]\n",
        "vocab[\"cosine\"] = cosine_list\n",
        "vocab.nlargest(10, \"cosine\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prompt is: Instrument for performing calculations by sliding beads along rods or grooves\n",
            "sent1_vec is a numpy array of shape: (512,)\n",
            "our vocab has 12619 words from which we will find the ones closest to our sentence...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vocab_word</th>\n",
              "      <th>cosine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abacus</td>\n",
              "      <td>0.361816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>calculations</td>\n",
              "      <td>0.336181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2405</th>\n",
              "      <td>calculation</td>\n",
              "      <td>0.305555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6389</th>\n",
              "      <td>instruments</td>\n",
              "      <td>0.305101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>grooves</td>\n",
              "      <td>0.302247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12417</th>\n",
              "      <td>wind instrument</td>\n",
              "      <td>0.292259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>beads</td>\n",
              "      <td>0.290021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6388</th>\n",
              "      <td>instrument</td>\n",
              "      <td>0.284906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>Instrument</td>\n",
              "      <td>0.284906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7695</th>\n",
              "      <td>musical instrument</td>\n",
              "      <td>0.276964</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               vocab_word    cosine\n",
              "2                  abacus  0.361816\n",
              "148          calculations  0.336181\n",
              "2405          calculation  0.305555\n",
              "6389          instruments  0.305101\n",
              "399               grooves  0.302247\n",
              "12417     wind instrument  0.292259\n",
              "104                 beads  0.290021\n",
              "6388           instrument  0.284906\n",
              "471            Instrument  0.284906\n",
              "7695   musical instrument  0.276964"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74M1_PAWB3w8"
      },
      "source": [
        "The Transformer based USE model is pretty accurate in and of itself, whereas the DAN is not so accurate. But we want to model a \"human\" version of this model, so we can add some stochastic noise to these estimates for both models eventually"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlDMgQchCzZ9"
      },
      "source": [
        "# Create phoneme function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgMBYBZNjBIS"
      },
      "source": [
        "Here we create a function that takes any letter string and partitions it into phonemes based on arpabet. Then we compute a measure of \"normalized\" phonemic similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0phmKU8C2GW",
        "outputId": "0960ac49-510e-43b2-f28b-0de2047db5ec"
      },
      "source": [
        "# algo to obtain phonemes for any given strng\n",
        "# obtained from: https://stackoverflow.com/questions/33666557/get-phonemes-from-any-word-in-python-nltk-or-other-modules\n",
        "try:\n",
        "    arpabet = nltk.corpus.cmudict.dict()\n",
        "except LookupError:\n",
        "    nltk.download('cmudict')\n",
        "    arpabet = nltk.corpus.cmudict.dict()\n",
        "\n",
        "@lru_cache()\n",
        "def wordbreak(s):\n",
        "    s = s.lower()\n",
        "    if s in arpabet:\n",
        "        return arpabet[s]\n",
        "    middle = len(s)/2\n",
        "    partition = sorted(list(range(len(s))), key=lambda x: (x-middle)**2-x)\n",
        "    for i in partition:\n",
        "        pre, suf = (s[:i], s[i:])\n",
        "        if pre in arpabet and wordbreak(suf) is not None:\n",
        "            return [x+y for x,y in iterprod(arpabet[pre], wordbreak(suf))]\n",
        "    return None\n",
        "\n",
        "def normalized_sim(w1, w2):\n",
        "  return 1-edit_distance(w1,w2)/(max(len(w1), len(w2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yep5HnUC7Qz",
        "outputId": "2017a3e3-6411-4b2c-d244-649afd31df4b"
      },
      "source": [
        "w1 = \"bird\"\n",
        "w2 = \"burden\"\n",
        "print(\"wordbreak(w1)[0]:\",wordbreak(w1)[0])\n",
        "print(\"wordbreak(w2)[0]:\",wordbreak(w2)[0])\n",
        "\n",
        "print(\"normalized orthographic similarity (letters):\", normalized_sim(w1, w2))\n",
        "print(\"normalized phonemic similarity:\", normalized_sim(wordbreak(w1)[0],wordbreak(w2)[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wordbreak(w1)[0]: ['B', 'ER1', 'D']\n",
            "wordbreak(w2)[0]: ['B', 'ER1', 'D', 'AH0', 'N']\n",
            "normalized orthographic similarity (letters): 0.5\n",
            "normalized phonemic similarity: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwBRDTKA7CPm"
      },
      "source": [
        "## semantic "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "725XJuMrhS0B"
      },
      "source": [
        "Below we get cosines from the prompt to the different primes and targets in our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob6NA8PgAZII",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "b93904f3-fb6b-48d3-fc8f-5bd5bc9e748f"
      },
      "source": [
        "## get cosines for:\n",
        "# 1. prompt - target\n",
        "# 2. prompt - primes\n",
        "# 3. prompt - resp\n",
        "\n",
        "both_prompt = []\n",
        "neither_prompt = []\n",
        "phon_prompt = []\n",
        "sem_prompt = []\n",
        "prime_prompt = []\n",
        "target_prompt = []\n",
        "resp_prompt = []\n",
        "\n",
        "# 4. target- primes\n",
        "target_both = []\n",
        "target_neither = []\n",
        "target_sem = []\n",
        "target_phon = []\n",
        "target_prime = []\n",
        "# 5. target - answer\n",
        "target_resp = []\n",
        "\n",
        "\n",
        "for index, row in julie_files.iterrows():\n",
        "  prompt_vec = model([row[\"prompt\"]])[0]\n",
        "  target_vec = model([row[\"Target\"]])[0]\n",
        "  resp = re.sub('[^a-zA-Z]+', '', str(row[\"Resp\"]))\n",
        "  prime = str(row[\"Prime\"])\n",
        "  #print(\"resp =\", resp)\n",
        "  \n",
        "\n",
        "  both_prompt_sim = cosine(prompt_vec, model([row[\"Both\"]])[0])\n",
        "  both_prompt.append(both_prompt_sim)\n",
        "\n",
        "  neither_prompt_sim = cosine(prompt_vec, model([row[\"Neither\"]])[0])\n",
        "  neither_prompt.append(neither_prompt_sim)\n",
        "\n",
        "  phon_prompt_sim = cosine(prompt_vec, model([row[\"Phonological\"]])[0])\n",
        "  phon_prompt.append(phon_prompt_sim)\n",
        "\n",
        "  sem_prompt_sim = cosine(prompt_vec, model([row[\"Semantic\"]])[0])\n",
        "  sem_prompt.append(sem_prompt_sim)\n",
        "\n",
        "  prime_prompt_sim = cosine(prompt_vec, model([prime])[0])\n",
        "  prime_prompt.append(prime_prompt_sim)\n",
        "\n",
        "  target_prompt_sim = cosine(prompt_vec, model([row[\"Target\"]])[0])\n",
        "  target_prompt.append(target_prompt_sim)\n",
        "  \n",
        "  resp_prompt_sim = cosine(prompt_vec, model([resp])[0]) if resp != \"\" else \"NA\"\n",
        "  resp_prompt.append(resp_prompt_sim)\n",
        "  \n",
        "\n",
        "  #4. target- primes\n",
        "  target_both_sim = cosine(target_vec, model([row[\"Both\"]])[0])\n",
        "  target_both.append(target_both_sim)\n",
        "\n",
        "  target_neither_sim = cosine(target_vec, model([row[\"Neither\"]])[0])\n",
        "  target_neither.append(target_neither_sim)\n",
        "\n",
        "  target_sem_sim = cosine(target_vec, model([row[\"Semantic\"]])[0])\n",
        "  target_sem.append(target_sem_sim)\n",
        "\n",
        "  target_phon_sim = cosine(target_vec, model([row[\"Phonological\"]])[0])\n",
        "  target_phon.append(target_phon_sim)\n",
        "\n",
        "  target_prime_sim = cosine(target_vec, model([prime])[0])\n",
        "  target_prime.append(target_prime_sim)\n",
        "\n",
        "  # 5. target - answer\n",
        "  target_resp_sim = cosine(target_vec, model([resp])[0]) if resp != \"\" else \"NA\"\n",
        "  target_resp.append(target_resp_sim)\n",
        "\n",
        "\n",
        "julie_files[\"both_prompt\"]  = both_prompt\n",
        "julie_files[\"neither_prompt\"]  = neither_prompt\n",
        "julie_files[\"sem_prompt\"]  = sem_prompt\n",
        "julie_files[\"phon_prompt\"]  = phon_prompt\n",
        "\n",
        "julie_files[\"prime_prompt\"]  = prime_prompt\n",
        "julie_files[\"target_prompt\"]  = target_prompt\n",
        "julie_files[\"resp_prompt\"]  = resp_prompt\n",
        "\n",
        "julie_files[\"target_both\"]  = target_both\n",
        "julie_files[\"target_neither\"]  = target_neither\n",
        "julie_files[\"target_sem\"]  = target_sem\n",
        "julie_files[\"target_phon\"]  = target_phon\n",
        "julie_files[\"target_prime\"]  = target_prime\n",
        "julie_files[\"target_resp\"]  = target_resp\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1cd1a7a2678c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;31m# 5. target - answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   \u001b[0mtarget_resp_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NA\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0mtarget_resp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_resp_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36m_call_attribute\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_attribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqUNfel34uOF"
      },
      "source": [
        "## phon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkUPd0LEha6-"
      },
      "source": [
        "Below we get estimates of phonemic similarity from the prompt to the different primes and targets in our data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa1phbpr4cA2"
      },
      "source": [
        "## get normalized phonemic similarities for:\n",
        "\n",
        "# 4. target- primes\n",
        "target_both = []\n",
        "target_neither = []\n",
        "target_sem = []\n",
        "target_phon = []\n",
        "target_prime = []\n",
        "# 5. target - answer\n",
        "target_resp = []\n",
        "\n",
        "\n",
        "for index, row in julie_files.iterrows():\n",
        "  \n",
        "  resp = re.sub('[^a-zA-Z]+', '', str(row[\"Resp\"]))\n",
        "  semantic = re.sub('[^a-zA-Z]+', '', str(row[\"Semantic\"]))\n",
        "  phono = re.sub('[^a-zA-Z]+', '', str(row[\"Phonological\"]))\n",
        "  neither = re.sub('[^a-zA-Z]+', '', str(row[\"Neither\"]))\n",
        "  both = re.sub('[^a-zA-Z]+', '', str(row[\"Both\"]))\n",
        "  \n",
        "\n",
        "  prime = re.sub('[^a-zA-Z]+', '', str(row[\"Prime\"]))\n",
        "  #print(\"resp =\", resp)\n",
        "  \n",
        "\n",
        "  #4. target- primes\n",
        "  target_both_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(both)[0])\n",
        "  target_both.append(target_both_sim)\n",
        "\n",
        "  target_neither_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(neither)[0])\n",
        "  target_neither.append(target_neither_sim)\n",
        "\n",
        "  target_sem_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(semantic)[0])\n",
        "  target_sem.append(target_sem_sim)\n",
        "\n",
        "  target_phon_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(phono)[0])\n",
        "  target_phon.append(target_phon_sim)\n",
        "\n",
        "  target_prime_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(prime)[0])\n",
        "  target_prime.append(target_prime_sim)\n",
        "\n",
        "  # 5. target - answer\n",
        "  target_resp_sim = normalized_sim(wordbreak(row[\"Target\"])[0],wordbreak(resp)[0]) if resp != \"\" else \"NA\"\n",
        "  target_resp.append(target_resp_sim)\n",
        "\n",
        "julie_files[\"lev_target_both\"]  = target_both\n",
        "julie_files[\"lev_target_neither\"]  = target_neither\n",
        "julie_files[\"lev_target_sem\"]  = target_sem\n",
        "julie_files[\"lev_target_phon\"]  = target_phon\n",
        "julie_files[\"lev_target_prime\"]  = target_prime\n",
        "julie_files[\"lev_target_resp\"]  = target_resp\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRpS5r589YRv"
      },
      "source": [
        "julie_files.to_csv(\"/content/drive/My Drive/LexicalRetrieval-2021/Julie_2021data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2rStY1ShjaX"
      },
      "source": [
        "# Modeling Ideas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_ZuyN4hhmKq"
      },
      "source": [
        "Some ways to think about how to \"model\" the task:\n",
        "\n",
        "\n",
        "1. After obtaining the representation for the prompt and all words in the vocabulary, start an \"activation\" process such that at t = 0, activation \"spreads\" from the prompt to all words in proportion to their similarity to the prompt\n",
        "2. At t=1, those words further spread activation to their neighbors.\n",
        "3. This could continue for \"t\" time steps technically, but we can also introduce a prime at some time step. This \"prime\" gets some extra boost of activation (+5 units, say), and then similarities are assessed as a combination of prompt and cue to ultimately produce the response. \n",
        "4. Maybe the ideal way to do this is an \"activation\" matrix of size vocab x 1 for both semantic and phonology and then we merge the two eventually?\n",
        "5. We may want to add in some stochastic noise to simulate partial knowledge in these models to see how that changes things\n",
        "6. So a general process model might be:\n",
        "*   activate_prompt_neighbors(noise) returns a 1-d array of similarities to every word in the vocab\n",
        "*   activate_prime_neighbors(noise) returns two N-by-1 arrays of similarities+activation corresponding to semantic and phonological similarities\n",
        "*   combine_semantic_phonological(method = \"additive | multiplicative\") returns a single N-by-1 array corresponding to combined sem-phon similarities after the promot and prime activations have been activated\n",
        "*   generate_predictions() returns a softmax of the activated matrix\n",
        "7. Ultimately, we want to make the code below efficient, and simulate about 100 participant runs with different levels of \"noise\" corresponding to levels of knowledge to obtain different model predictions\n",
        "8. Also, we may want to have a parameter that controls the weight to semantic vs. phonological information in the \"combine\" function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GLm2F7xFkjF"
      },
      "source": [
        "## model functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2zZTc7w_MY6",
        "outputId": "f72a498c-914a-4b6b-d83e-ec5be9e6dbbd"
      },
      "source": [
        "def initial_activation(vocab_words):\n",
        "  # returns an array of initial activations, currently zero, but eventually replace by word frequency\n",
        "  x = np.zeros((len(vocab_words),1)).T\n",
        "  return x\n",
        "\n",
        "initial_activation(vocab).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 12619)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_NpIO8BF_v6"
      },
      "source": [
        "def activate_prompt_neighbors(activations, vocab_words, prompt, noise_level):\n",
        "  ## takes in a 1-d array of current activations\n",
        "  ## computes a vector representation of the prompt and returns a vector of similarities to each word in vocab + activations\n",
        "  ## with some noise added to each estimate\n",
        "  noise = np.random.normal(0, noise_level, 1)\n",
        "  prompt_vec = model([prompt])[0]\n",
        "  resp = list(vocab_words.vocab_word)\n",
        "  cosine_list = np.array([cosine(prompt_vec, model([r])[0]) for r in resp]) + activations # eventually add noise\n",
        "  return cosine_list\n",
        "\n",
        "x = activate_prompt_neighbors(initial_activation(vocab), vocab, \"capital of Finland\", 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOUJoydQMZk0",
        "outputId": "e78edb2b-f84c-4229-8791-d17c29cef932"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 12619)"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Eo-nYLGBrF"
      },
      "source": [
        "def activate_prime_neighbors(activations_sem, vocab_words, prime):\n",
        "  ## takes in a 1-d array of semantic activations and returns \"primed\" activations for both semantic and phonological\n",
        "  prime_vec = model([prime])[0]\n",
        "  resp = list(vocab_words.vocab_word)\n",
        "  semantic = (np.array([cosine(prime_vec, model([r])[0]) for r in resp]) + activations_sem)\n",
        "  phon = np.array([normalized_sim(r, prime) for r in resp]).reshape(semantic.shape)\n",
        "  assert semantic.shape == phon.shape\n",
        "  return semantic, phon\n",
        "\n",
        "y, z = activate_prime_neighbors(x, vocab, 'Oslo')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLqfertJKXeH"
      },
      "source": [
        "def combine_semantic_phonological(semantic, phonological, method = \"multiply\"): #TODO: add alpha arg for add only\n",
        "  if method == \"add\":\n",
        "    comb = np.add(semantic, phonological)\n",
        "  else:\n",
        "    comb = np.multiply(semantic, phonological)\n",
        "  \n",
        "  return softmax(comb)\n",
        "\n",
        "final_activations = combine_semantic_phonological(y, z, method = \"add\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI53gxtIRWgf",
        "outputId": "23ec1a46-d628-4027-87c7-ea009f4daf4c"
      },
      "source": [
        "def generate_predictions(activations, vocab_words, topn = 10):\n",
        "  ## takes in final activations and generates the top10 predictions\n",
        "  return [list(vocab_words.vocab_word)[i] for i in np.argpartition(-activations, topn).flatten().tolist()[:topn]]\n",
        "\n",
        "generate_predictions(final_activations, vocab, topn = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Stockholm',\n",
              " 'Helsinki',\n",
              " 'Finland',\n",
              " 'Oslo',\n",
              " 'Boston',\n",
              " 'Norway',\n",
              " 'Czechoslovakia',\n",
              " 'Oswald',\n",
              " 'pilot',\n",
              " 'Nordic']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS7RFXfSRzaE"
      },
      "source": [
        "def lexical_retrieval_model(prompt, prime, vocab_words):\n",
        "  ## brings all functions together\n",
        "  init = initial_activation(vocab_words)\n",
        "  x = activate_prompt_neighbors(init, vocab_words, prompt, 0.1)\n",
        "  y, z = activate_prime_neighbors(x, vocab, prime)\n",
        "  final_add = combine_semantic_phonological(y, z, method = \"add\")\n",
        "  final_mult = combine_semantic_phonological(y, z, method = \"multiply\")\n",
        "  preds_add = generate_predictions(final_add, vocab_words, topn = 10)\n",
        "  preds_mult = generate_predictions(final_mult, vocab_words, topn = 10)\n",
        "\n",
        "  return preds_add, preds_mult"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtrhb3jwc7h9"
      },
      "source": [
        "def accuracy_single(trial, vocab_words, n, method):\n",
        "  # returns 1 if the target if the target is in the top n predictions, else 0\n",
        "  t = trial - 1\n",
        "  #print(\"prompt:\", julie_files[\"prompt\"][t])\n",
        "  #print(\"target:\", julie_files[\"Target\"][t])\n",
        "  #print(\"prime:\", julie_files[\"Prime\"][t])\n",
        "  add, mult = lexical_retrieval_model(julie_files[\"prompt\"][t], julie_files[\"Prime\"][t].lower(), vocab_words) #The Prime column is all uppercase. Does that matter?\n",
        "  topn = add[:n] if method == \"add\" else mult[:n]\n",
        "  #print(topn)\n",
        "  if julie_files[\"Target\"][t] in topn:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "def accuracy_overall(vocab_words, n=10,):\n",
        "  # returns the overall probability that the target will appear in the top n words predicted by the model\n",
        "  acc_add = np.mean([accuracy_single(t, vocab_words, n, \"add\") for t in julie_files[\"Trial\"].to_list()])\n",
        "  acc_mult = np.mean([accuracy_single(t, vocab_words, n, \"mult\") for t in julie_files[\"Trial\"].to_list()])\n",
        "  print(\"Accuracy of additive model:\", acc_add)\n",
        "  print(\"Accuracy of multiplicative model:\", acc_mult)\n",
        "  return acc_add, acc_mult"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dovHmQAiwoT6"
      },
      "source": [
        "# plot accuracy as a function of n for both add and mult \n",
        "nvals = [i for i in range(5, 11)] #change upper bound depending on value of topn used in generate_predictions()\n",
        "plt.plot(nvals, accuracy_overall(vocab, nvals)[0], 'r--', nvals, accuracy_overall(vocab, nvals)[1]) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOLXKbovY4U7"
      },
      "source": [
        "# model predictions: examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sskbdFgUTPPT",
        "outputId": "3d41f1e8-cee0-4869-fe05-8aec50ea818a"
      },
      "source": [
        "add, mult = lexical_retrieval_model(\"Capital of Finland\", \"Helsinki\", vocab)\n",
        "print(\"predictions for additive model:\", add)\n",
        "print(\"predictions for multiplicative model:\", mult)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predictions for additive model: ['Helsinki', 'Finland', 'Czechoslovakia', 'Oslo', 'Nordic', 'Sweden', 'Berlin', 'Holland', 'Iceland', 'Celtic']\n",
            "predictions for multiplicative model: ['Holland', 'Czechoslovakia', 'Berlin', 'Celtic', 'Helsinki', 'ski', 'Alpine', 'herring', 'Pilsen', 'clingy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4aWABnETWbk",
        "outputId": "93fa0ab7-aec8-45d1-f41f-93f86cb47676"
      },
      "source": [
        "add, mult = lexical_retrieval_model(\"A mathematical expression consisting of two terms\", \"bilateral\", vocab)\n",
        "print(\"predictions for additive model:\", add)\n",
        "print(\"predictions for multiplicative model:\", mult)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predictions for additive model: ['biannual', 'bilateral', 'integral', 'mathematical', 'bisexual', 'partial', 'paternal', 'interval', 'binomial', 'mutual']\n",
            "predictions for multiplicative model: ['bilateral', 'biannual', 'integral', 'binomial', 'paternal', 'interval', 'bisexual', 'partial', 'plural', 'mathematical']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiGUMx5ZWhvp",
        "outputId": "5bafc958-b52e-4ee5-c8bc-56d98b914039"
      },
      "source": [
        "add, mult = lexical_retrieval_model(\"Identical in form; coinciding exactly when superimposed\", \"cognizant\", vocab)\n",
        "print(\"predictions for additive model:\", add)\n",
        "print(\"predictions for multiplicative model:\", mult)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "predictions for additive model: ['constant', 'cognition', 'cognizant', 'cognitive', 'confidant', 'confident', 'congruent', 'ignorant', 'coinciding', 'recognition']\n",
            "predictions for multiplicative model: ['cognition', 'cognizant', 'cognitive', 'confident', 'confidant', 'constant', 'recognition', 'ignorant', 'coinciding', 'congruent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZGs7LTRXjFZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}